#!/usr/bin/env bash
set -euo pipefail

# Configuration
DEFAULT_FLAGS=()
# readonly IMAGE_NAME="claudebox"  # Now computed per project
readonly DOCKER_USER="claude"
readonly USER_ID=$(id -u)
readonly GROUP_ID=$(id -g)
readonly PROJECT_DIR="$(pwd)"

# ────────────────────────────────────────────────────────────────────────────────
#  Cross-platform host detection (Linux vs. macOS) and FS case-sensitivity check
# ────────────────────────────────────────────────────────────────────────────────
OS_TYPE="$(uname -s)"
case "$OS_TYPE" in
  Darwin*) HOST_OS="macOS" ;;
  Linux*)  HOST_OS="linux" ;;
  *) echo "Unsupported operating system: $OS_TYPE" >&2; exit 1 ;;
esac

# Detect case‑insensitive default macOS filesystems (HFS+/APFS)
# Exit code 0  → case‑sensitive, 1 → case‑insensitive
is_case_sensitive_fs() {
  local t1 t2
  t1="$(mktemp "/tmp/.fs_case_test.XXXXXXXX")"
  t2="${t1^^}"          # same name, different case
  touch "$t1"
  [[ -e "$t2" && "$t1" != "$t2" ]] && { rm -f "$t1"; return 1; }
  rm -f "$t1"
  return 0
}

# Normalise docker‑build contexts on case‑insensitive hosts to avoid collisions
if [[ "$HOST_OS" == "macOS" ]] && ! is_case_sensitive_fs; then
  export COMPOSE_DOCKER_CLI_BUILD=1   # new BuildKit path‑normaliser
  export DOCKER_BUILDKIT=1
fi

# Cross-platform script path resolution
get_script_path() {
    local source="${BASH_SOURCE[0]:-$0}"
    while [[ -L "$source" ]]; do
        local dir="$(cd -P "$(dirname "$source")" && pwd)"
        source="$(readlink "$source")"
        [[ $source != /* ]] && source="$dir/$source"
    done
    echo "$(cd -P "$(dirname "$source")" && pwd)/$(basename "$source")"
}
readonly SCRIPT_PATH="$(get_script_path)"

readonly CLAUDE_DATA_DIR="$HOME/.claude"
readonly LINK_TARGET="$HOME/.local/bin/claudebox"
readonly NODE_VERSION="--lts"
readonly DELTA_VERSION="0.17.0"

# Color codes
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly PURPLE='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly WHITE='\033[1;37m'
readonly NC='\033[0m'

# Utility functions
cecho() { echo -e "${2:-$NC}$1${NC}"; }
error() { cecho "$1" "$RED" >&2; exit "${2:-1}"; }
warn() { cecho "$1" "$YELLOW"; }
info() { cecho "$1" "$BLUE"; }
success() { cecho "$1" "$GREEN"; }

# Parse early flags
VERBOSE=false
ENABLE_SUDO=false
DISABLE_FIREWALL=false
DOCKER_ARGS=()

for arg in "$@"; do
    case "$arg" in
        --verbose) VERBOSE=true ; shift ;;
    esac
done

# Load saved default flags if they exist
if [[ -f "$HOME/.claudebox/default-flags" ]]; then
    while IFS= read -r flag; do
        [[ -n "$flag" ]] && DEFAULT_FLAGS+=("$flag")
    done < "$HOME/.claudebox/default-flags"
fi

# Logo
logo() {
    local cb='
 ██████╗██╗      █████╗ ██╗   ██╗██████╗ ███████╗
██╔════╝██║     ██╔══██╗██║   ██║██╔══██╗██╔════╝
██║     ██║     ███████║██║   ██║██║  ██║█████╗
██║     ██║     ██╔══██║██║   ██║██║  ██║██╔══╝
╚██████╗███████╗██║  ██║╚██████╔╝██████╔╝███████╗
 ╚═════╝╚══════╝╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝

██████╗  ██████╗ ██╗  ██╗ ------ ┌──────────────┐
██╔══██╗██╔═══██╗╚██╗██╔╝ ------ │ The Ultimate │
██████╔╝██║   ██║ ╚███╔╝  ------ │ Claude Code  │
██╔══██╗██║   ██║ ██╔██╗  ------ │  Docker Dev  │
██████╔╝╚██████╔╝██╔╝ ██╗ ------ │ Environment  │
╚═════╝  ╚═════╝ ╚═╝  ╚═╝ ------ └──────────────┘
'
    while IFS= read -r l; do
        o="" c=""
        for ((i=0;i<${#l};i++)); do
            ch="${l:$i:1}"
            [[ "$ch" == " " ]] && { o+="$ch"; continue; }
            cc=$(printf '%d' "'$ch" 2>/dev/null||echo 0)
            if [[ $cc -ge 32 && $cc -le 126 ]]; then n='\033[33m'
            elif [[ $cc -ge 9552 && $cc -le 9580 ]]; then n='\033[34m'
            elif [[ $cc -eq 9608 ]]; then n='\033[31m'
            else n='\033[37m'; fi
            [[ "$n" != "$c" ]] && { o+="$n"; c="$n"; }
            o+="$ch"
        done
        echo -e "${o}\033[0m"
    done <<< "$cb"
}

update_symlink() {
    # Ensure the directory exists
    mkdir -p "$(dirname "$LINK_TARGET")"

    # Check if symlink exists and points to the correct location
    if [[ -L "$LINK_TARGET" ]]; then
        local current_target
        current_target=$(readlink "$LINK_TARGET" 2>/dev/null || echo "")
        if [[ "$current_target" == "$SCRIPT_PATH" ]]; then
            [[ "$VERBOSE" == "true" ]] && info "Symlink already correct: $LINK_TARGET → $SCRIPT_PATH"
            return 0
        else
            # Remove incorrect symlink
            rm -f "$LINK_TARGET"
            [[ "$VERBOSE" == "true" ]] && info "Removing outdated symlink"
        fi
    elif [[ -e "$LINK_TARGET" ]]; then
        # Something else exists at this path
        error "Cannot create symlink: $LINK_TARGET already exists and is not a symlink"
    fi

    # Create new symlink
    if ln -s "$SCRIPT_PATH" "$LINK_TARGET"; then
        success "Symlink updated: $LINK_TARGET → $SCRIPT_PATH"
    else
        warn "Could not create symlink at $LINK_TARGET"
        warn "Try running with sudo or ensure $(dirname "$LINK_TARGET") is writable"
        warn "Error: $?"
    fi
}

# Docker checks
check_docker() {
    command -v docker &>/dev/null || return 1
    docker info &>/dev/null || return 2
    docker ps &>/dev/null || return 3
    return 0
}

install_docker() {
    warn "Docker is not installed."
    cecho "Would you like to install Docker now? (y/n)" "$CYAN"
    read -r response
    [[ "$response" =~ ^[Yy]$ ]] || error "Docker is required. Visit: https://docs.docker.com/engine/install/"

    info "Installing Docker..."

    [[ -f /etc/os-release ]] && . /etc/os-release || error "Cannot detect OS"

    case "${ID:-}" in
        ubuntu|debian)
            warn "Installing Docker requires sudo privileges..."
            sudo apt-get update
            sudo apt-get install -y ca-certificates curl gnupg lsb-release
            sudo mkdir -p /etc/apt/keyrings
            curl -fsSL "https://download.docker.com/linux/$ID/gpg" | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/$ID $(lsb_release -cs) stable" | \
                sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            sudo apt-get update
            sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            ;;
        fedora|rhel|centos)
            warn "Installing Docker requires sudo privileges..."
            sudo dnf -y install dnf-plugins-core
            sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo
            sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            sudo systemctl start docker
            sudo systemctl enable docker
            ;;
        arch|manjaro)
            warn "Installing Docker requires sudo privileges..."
            sudo pacman -S --noconfirm docker
            sudo systemctl start docker
            sudo systemctl enable docker
            ;;
        *)
            error "Unsupported OS: ${ID:-unknown}. Visit: https://docs.docker.com/engine/install/"
            ;;
    esac

    success "Docker installed successfully!"
    configure_docker_nonroot
}

configure_docker_nonroot() {
    warn "Configuring Docker for non-root usage..."
    warn "This requires sudo to add you to the docker group..."

    getent group docker >/dev/null || sudo groupadd docker
    sudo usermod -aG docker "$USER"

    success "Docker configured for non-root usage!"
    warn "You need to log out and back in for group changes to take effect."
    warn "Or run: ${CYAN}newgrp docker"
    warn "Then run 'claudebox' again."
    info "Trying to activate docker group in current shell..."
    exec newgrp docker
}

# Spinner
show_spinner() {
    local pid=$1 msg=$2 spin='⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏' i=0
    echo -n "$msg "
    while kill -0 "$pid" 2>/dev/null; do
        printf "\b%s" "${spin:i++%${#spin}:1}"
        sleep 0.1
    done
    echo -e "\b${GREEN}✓${NC}"
}

declare -A PROFILES PROFILE_DESCRIPTIONS

# Shared base
PROFILES[core]="gcc g++ make git pkg-config libssl-dev libffi-dev zlib1g-dev"
PROFILE_DESCRIPTIONS[core]="Core Development Utilities (compilers, VCS, shell tools)"

# Optional build helpers
PROFILES[build-tools]="cmake ninja-build autoconf automake libtool"
PROFILE_DESCRIPTIONS[build-tools]="Build Tools (CMake, autotools, Ninja)"

# Shell / net / file utilities (optional)
PROFILES[shell]="rsync openssh-client man-db gnupg2 aggregate file"
PROFILE_DESCRIPTIONS[shell]="Optional Shell Tools (fzf, SSH, man, rsync, file)"

PROFILES[networking]="iptables ipset iproute2 dnsutils"
PROFILE_DESCRIPTIONS[networking]="Network Tools (IP stack, DNS, route tools)"

# Domain-specific
PROFILES[c]="gdb valgrind clang clang-format clang-tidy cppcheck doxygen libboost-all-dev libcmocka-dev libcmocka0 lcov libncurses5-dev libncursesw5-dev"
PROFILE_DESCRIPTIONS[c]="C/C++ Development (debuggers, analyzers, Boost, ncurses, cmocka)"

PROFILES[openwrt]="rsync libncurses5-dev zlib1g-dev gawk gettext xsltproc libelf-dev ccache subversion swig time qemu-system-arm qemu-system-aarch64 qemu-system-mips qemu-system-x86 qemu-utils"
PROFILE_DESCRIPTIONS[openwrt]="OpenWRT Development (cross toolchain, QEMU, distro tools)"

PROFILES[rust]=""  # Rust installed via rustup
PROFILE_DESCRIPTIONS[rust]="Rust Development (installed via rustup)"

PROFILES[python]=""  # Managed via uv
PROFILE_DESCRIPTIONS[python]="Python Development (managed via uv)"

PROFILES[go]=""  # Installed from tarball
PROFILE_DESCRIPTIONS[go]="Go Development (installed from upstream archive)"

PROFILES[javascript]=""  # Installed via nvm
PROFILE_DESCRIPTIONS[javascript]="JavaScript/TypeScript (Node installed via nvm)"

PROFILES[java]="openjdk-17-jdk maven gradle ant"
PROFILE_DESCRIPTIONS[java]="Java Development (OpenJDK 17, Maven, Gradle, Ant)"

PROFILES[ruby]="ruby-full ruby-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libcurl4-openssl-dev software-properties-common"
PROFILE_DESCRIPTIONS[ruby]="Ruby Development (gems, native deps, XML/YAML)"

PROFILES[php]="php php-cli php-fpm php-mysql php-pgsql php-sqlite3 php-curl php-gd php-mbstring php-xml php-zip composer"
PROFILE_DESCRIPTIONS[php]="PHP Development (PHP + extensions + Composer)"

PROFILES[database]="postgresql-client mysql-client sqlite3 redis-tools mongodb-clients"
PROFILE_DESCRIPTIONS[database]="Database Tools (clients for major databases)"

PROFILES[devops]="docker.io docker-compose kubectl helm terraform ansible awscli"
PROFILE_DESCRIPTIONS[devops]="DevOps Tools (Docker, Kubernetes, Terraform, etc.)"

PROFILES[web]="nginx apache2-utils httpie"
PROFILE_DESCRIPTIONS[web]="Web Dev Tools (nginx, HTTP test clients)"

PROFILES[embedded]="gcc-arm-none-eabi gdb-multiarch openocd picocom minicom screen platformio"
PROFILE_DESCRIPTIONS[embedded]="Embedded Dev (ARM toolchain, serial debuggers)"

PROFILES[datascience]="r-base"
PROFILE_DESCRIPTIONS[datascience]="Data Science (Python, Jupyter, R)"

PROFILES[security]="nmap tcpdump wireshark-common netcat-openbsd john hashcat hydra"
PROFILE_DESCRIPTIONS[security]="Security Tools (scanners, crackers, packet tools)"

PROFILES[ml]=""  # Just cmake needed, comes from build-tools now
PROFILE_DESCRIPTIONS[ml]="Machine Learning (build layer only; Python via uv)"


expand_profile() {
    case "$1" in
        c) echo "core build-tools c" ;;
        openwrt) echo "core build-tools openwrt" ;;
        ml) echo "core build-tools ml" ;;
        rust|go|python|php|ruby|java|database|devops|web|embedded|datascience|security|javascript)
            echo "core $1"
            ;;
        shell|networking|build-tools|core)
            echo "$1"
            ;;
        *)
            echo "$1"
            ;;
    esac
}



# Docker operations
docker_exec_root() {
    docker exec -u root "$@"
}

docker_exec_user() {
    docker exec -u "$DOCKER_USER" "$@"
}

# Helper functions for project profiles
get_project_folder_name() {
    echo "$1" | sed 's|^/||; s|[^a-zA-Z0-9]|_|g; s|_+|_|g; s|^_||; s|_$||'
}

get_profile_file_path() {
    local profile_dir="$HOME/.claudebox/profiles"
    mkdir -p "$profile_dir"
    echo "$profile_dir/$(echo "$PROJECT_DIR" | sed 's|/|-|g' | sed 's|^-||').ini"
}

read_profile_section() {
    local profile_file="$1"
    local section="$2"
    local result=()

    if [[ -f "$profile_file" ]] && grep -q "^\[$section\]" "$profile_file"; then
        while IFS= read -r line; do
            [[ -z "$line" || "$line" =~ ^\[.*\]$ ]] && break
            result+=("$line")
        done < <(sed -n "/^\[$section\]/,/^\[/p" "$profile_file" | tail -n +2 | grep -v '^\[')
    fi

    printf '%s\n' "${result[@]}"
}

update_profile_section() {
    local profile_file="$1"
    local section="$2"
    shift 2
    local new_items=("$@")

    # Read existing items
    local existing_items=()
    readarray -t existing_items < <(read_profile_section "$profile_file" "$section")

    # Merge with new items (avoid duplicates)
    local all_items=()
    for item in "${existing_items[@]}"; do
        [[ -n "$item" ]] && all_items+=("$item")
    done

    for item in "${new_items[@]}"; do
        local found=false
        for existing in "${all_items[@]}"; do
            [[ "$existing" == "$item" ]] && found=true && break
        done
        [[ "$found" == "false" ]] && all_items+=("$item")
    done

    # Write updated profile file
    {
        # Preserve other sections
        if [[ -f "$profile_file" ]]; then
            awk -v sect="$section" '
                BEGIN { in_section=0; skip_section=0 }
                /^\[/ {
                    if ($0 == "[" sect "]") { skip_section=1; in_section=1 }
                    else { skip_section=0; in_section=0 }
                }
                !skip_section { print }
                /^\[/ && !skip_section && in_section { in_section=0 }
            ' "$profile_file"
        fi

        # Add our section
        echo "[$section]"
        for item in "${all_items[@]}"; do
            echo "$item"
        done
        echo ""
    } > "${profile_file}.tmp" && mv "${profile_file}.tmp" "$profile_file"
}

# Project-specific folder setup
setup_project_folder() {
    # Firewall configuration
    mkdir -p "$PROJECT_CLAUDEBOX_DIR/firewall"
    
    # Create mount points for Docker volumes
    mkdir -p "$PROJECT_CLAUDEBOX_DIR/.claude"
    mkdir -p "$PROJECT_CLAUDEBOX_DIR/.config"
    touch "$PROJECT_CLAUDEBOX_DIR/.claude.json"
    touch "$PROJECT_CLAUDEBOX_DIR/.zsh_history"
}


# Setup Claude agent command
setup_claude_agent_command() {
    mkdir -p .claude/commands
    cat << 'EOF' > .claude/commands/taskengine.md
<<SYSTEM>>
You are “TaskEngine”, an adaptive multi-agent pipeline for zero-deviation software delivery.
ROLES
------
1. Analyst – extract/clarify requirements, output FINAL_SPEC (bullets).
2. Planner  – decompose FINAL_SPEC into ordered TASKS.
3. Implementer – write minimal-scope, test-driven code for each TASK.
4. Critic – lint/style review; output PATCH_HINTS only.
5. Evaluator – run code & tests in isolation; output DEVIATIONS list.
   • Must never share context with Implementer beyond artefacts.
   • Must continue pipeline; never halt execution.
6. Orchestrator – monitor cycle, integrate PATCH_HINTS & DEVIATIONS,
   re-queue failed TASKS until Evaluator reports none.
   • Declare DONE when DEVIATIONS == Ø.
WORKFLOW
---------
1. Analyst: If spec incomplete, ask concise questions; else emit FINAL_SPEC.
2. Planner: Break FINAL_SPEC into atomic TASKS (≤ one pure function each).
3. For TASK in TASKS:
   a. Implementer → produce code + tests.
   b. Critic → emit PATCH_HINTS (optional).
   c. Implementer → apply PATCH_HINTS.
   d. Evaluator → execute; append any DEVIATIONS.
4. Orchestrator: If DEVIATIONS ≠ Ø, loop step 3; else continue.
5. When all TASKS pass Evaluator with DEVIATIONS == Ø → output COMPLETE_DELIVERABLE.
SIDE-EFFECT CONTROL
--------------------
Before executing external commands or installing tools:
  Implementer MUST emit:
    REQUEST-INSTALL-PERMISSION: <tool names>
Orchestrator waits for explicit “PERMISSION GRANTED” from user.
QUALITY GUARDRAILS
-------------------
* Enforce SOLID, DRY, KISS unless FINAL_SPEC forbids.
* Code and tests must be deterministic & idempotent.
* Any ambiguity → Analyst must clarify before planning.
* No speculative features beyond FINAL_SPEC.
OUTPUT STYLE
-------------
* Use triple-back-tick fenced blocks for code.
* Role names prefix every message: Analyst: …, Evaluator: ….
* Keep non-code text brief and factual.
BEGIN.
EOF
}

# Create files to copy into the image
create_build_files() {
    local build_context="$1"

    cat > "$build_context/init-firewall" << 'EOF'
#!/bin/bash
set -euo pipefail
if [ "${DISABLE_FIREWALL:-false}" = "true" ]; then
    echo "Firewall disabled, skipping setup"
    rm -f "$0"
    exit 0
fi
iptables -F OUTPUT 2>/dev/null || true
iptables -F INPUT 2>/dev/null || true
iptables -A OUTPUT -p udp --dport 53 -j ACCEPT
iptables -A OUTPUT -p tcp --dport 53 -j ACCEPT
iptables -A INPUT -p udp --sport 53 -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT
iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -s 127.0.0.0/8 -d 127.0.0.0/8 -j ACCEPT
iptables -A INPUT -s 127.0.0.0/8 -d 127.0.0.0/8 -j ACCEPT
iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
# Default allowed domains
DEFAULT_DOMAINS="api.anthropic.com console.anthropic.com statsig.anthropic.com sentry.io"

# Read additional domains from allowlist file if it exists
ALLOWED_DOMAINS="$DEFAULT_DOMAINS"
# Try project-specific allowlist first, then fall back to global
if [ -f /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/firewall/allowlist ]; then
    while IFS= read -r domain; do
        # Skip comments and empty lines
        [[ "$domain" =~ ^#.* ]] && continue
        [[ -z "$domain" ]] && continue
        # Remove wildcards for now (*.example.com becomes example.com)
        domain="${domain#\*.}"
        ALLOWED_DOMAINS="$ALLOWED_DOMAINS $domain"
    done < /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/firewall/allowlist
elif [ -f /home/DOCKERUSER/.claudebox/allowlist ]; then
    while IFS= read -r domain; do
        # Skip comments and empty lines
        [[ "$domain" =~ ^#.* ]] && continue
        [[ -z "$domain" ]] && continue
        # Remove wildcards for now (*.example.com becomes example.com)
        domain="${domain#\*.}"
        ALLOWED_DOMAINS="$ALLOWED_DOMAINS $domain"
    done < /home/DOCKERUSER/.claudebox/allowlist
fi

if command -v ipset >/dev/null 2>&1; then
    ipset destroy allowed-domains 2>/dev/null || true
    ipset create allowed-domains hash:net
    ipset destroy allowed-ips 2>/dev/null || true
    ipset create allowed-ips hash:net

    for domain in $ALLOWED_DOMAINS; do
        # Check if it's an IP range
        if [[ "$domain" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/[0-9]+$ ]]; then
            ipset add allowed-ips $domain 2>/dev/null || true
        else
            # It's a domain, resolve it
            ips=$(getent hosts $domain 2>/dev/null | awk '{print $1}')
            for ip in $ips; do
                ipset add allowed-domains $ip 2>/dev/null || true
            done
        fi
    done
    iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
    iptables -A OUTPUT -m set --match-set allowed-ips dst -j ACCEPT
else
    # Fallback without ipset
    for domain in $ALLOWED_DOMAINS; do
        if [[ "$domain" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/[0-9]+$ ]]; then
            iptables -A OUTPUT -d $domain -j ACCEPT
        else
            # Resolve domain to IPs
            ips=$(getent hosts $domain 2>/dev/null | awk '{print $1}')
            for ip in $ips; do
                iptables -A OUTPUT -d $ip -j ACCEPT
            done
        fi
    done
fi
iptables -P OUTPUT DROP
iptables -P INPUT DROP
echo "Firewall initialized with Anthropic-only access"
rm -f "$(realpath "$0")"
EOF

    cat > "$build_context/claude-wrapper" << 'EOF'
#!/bin/bash
set -euo pipefail

export NVM_DIR="$HOME/.nvm"

# Check if nvm exists before sourcing
if [[ -s "$NVM_DIR/nvm.sh" ]]; then
    \. "$NVM_DIR/nvm.sh"
    nvm use default >/dev/null 2>&1 || {
        echo "Warning: Failed to activate default Node version" >&2
    }
else
    echo "Warning: NVM not found at $NVM_DIR" >&2
fi
rm -f "$(realpath "$0")"
# Execute claude with all arguments
exec claude "$@"
EOF

    cat > "$build_context/docker-entrypoint.sh" << 'EOF'
#!/bin/bash
set -euo pipefail
ENABLE_SUDO=false
DISABLE_FIREWALL=false
new_args=()
while [[ $# -gt 0 ]]; do
    case "$1" in
        --enable-sudo) ENABLE_SUDO=true; shift ;;
        --disable-firewall) DISABLE_FIREWALL=true; shift ;;
        *) new_args+=("$1"); shift ;;
    esac
done
set -- "${new_args[@]}"
export DISABLE_FIREWALL

# Set up shared commands
if [ -d /home/DOCKERUSER/.claudebox/commands ]; then
    # Ensure .claude/commands directory exists
    mkdir -p /home/DOCKERUSER/.claude/commands
    
    # Copy shared commands (don't overwrite existing project-specific ones)
    cp -n /home/DOCKERUSER/.claudebox/commands/* /home/DOCKERUSER/.claude/commands/ 2>/dev/null || true
    
    # Ensure proper ownership
    chown -R DOCKERUSER:DOCKERUSER /home/DOCKERUSER/.claude
fi

if [ -f ~/init-firewall ]; then
    ~/init-firewall || true
fi
if [ "$ENABLE_SUDO" = "true" ]; then
    echo "DOCKERUSER ALL=(ALL) NOPASSWD:ALL" > /etc/sudoers.d/DOCKERUSER
    chmod 0440 /etc/sudoers.d/DOCKERUSER
fi

if [ -n "$CLAUDEBOX_PROJECT_NAME" ]; then
    PROFILE_FILE="/home/DOCKERUSER/.claudebox/profiles/${CLAUDEBOX_PROJECT_NAME}.ini"

    if command -v uv >/dev/null 2>&1 && [ -f "$PROFILE_FILE" ] && grep -qE 'python|ml|datascience' "$PROFILE_FILE"; then
        if [ ! -d /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv ]; then
            su - DOCKERUSER -c "uv venv /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv"
            if [ -f /workspace/pyproject.toml ]; then
                su - DOCKERUSER -c "cd /workspace && uv sync"
            else
                su - DOCKERUSER -c "uv pip install --python /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/python ipython black pylint mypy flake8 pytest ruff"
            fi
        fi

        for shell_rc in /home/DOCKERUSER/.zshrc /home/DOCKERUSER/.bashrc; do
            if ! grep -q "source /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/activate" "$shell_rc"; then
                echo 'if [ -f /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/activate ]; then source /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/activate; fi' >> "$shell_rc"
            fi
        done
    fi
fi

cd /home/DOCKERUSER
# Check if we're in shell mode
if [[ "${1:-}" == "--shell-mode" ]]; then
    shift  # Remove --shell-mode flag
    exec su DOCKERUSER -c "source /home/DOCKERUSER/.nvm/nvm.sh && cd /workspace && exec /bin/zsh"
else
    # Build command with properly quoted arguments
    cmd="cd /workspace && ~/claude-wrapper"
    for arg in "$@"; do
        # Escape single quotes in the argument
        escaped_arg=$(echo "$arg" | sed "s/'/'\\\\''/g")
        cmd="$cmd '$escaped_arg'"
    done
    exec su DOCKERUSER -c "$cmd"
fi
EOF
}

run_docker_build() {
    info "Running docker build..."
    # Force BuildKit for better performance and features
    DOCKER_BUILDKIT=1 docker build \
        --build-arg USER_ID="$USER_ID" \
        --build-arg GROUP_ID="$GROUP_ID" \
        --build-arg USERNAME="$DOCKER_USER" \
        --build-arg NODE_VERSION="$NODE_VERSION" \
        --build-arg DELTA_VERSION="$DELTA_VERSION" \
        -f "$1" -t "$IMAGE_NAME" "$2"
}

# Main execution
main() {
    update_symlink
    local project_folder_name
    project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
    IMAGE_NAME="claudebox-${project_folder_name}"
    # Check Docker
    local docker_status
    docker_status=$(check_docker; echo $?)
    case $docker_status in
        1) install_docker ;;
        2)
            warn "Docker is installed but not running."
            warn "Starting Docker requires sudo privileges..."
            sudo systemctl start docker
            docker info &>/dev/null || error "Failed to start Docker"
            docker ps &>/dev/null || configure_docker_nonroot
            ;;
        3)
            warn "Docker requires sudo. Setting up non-root access..."
            configure_docker_nonroot
            ;;
    esac

    # Check for rebuild, help, and verbose flags anywhere in arguments
    local args=("$@")
    local new_args=()
    local found_rebuild=false
    local found_help=false
    local VERBOSE=false

    for arg in "${args[@]}"; do
        if [[ "$arg" == "rebuild" ]]; then
            found_rebuild=true
        elif [[ "$arg" == "--verbose" ]]; then
            VERBOSE=true
            # strip it out so it doesn't become $1 later
        elif [[ "$arg" == "-h" || "$arg" == "--help" || "$arg" == "help" ]]; then
            # only global-help if it's literally the first token
            if [[ "${args[0]}" == "$arg" ]]; then
                found_help=true
            fi
            new_args+=("$arg")
        elif [[ "$arg" == "--enable-sudo" || "$arg" == "--disable-firewall" ]]; then
            # handled below
            continue
        else
            new_args+=("$arg")
        fi
    done

    if [[ "$found_rebuild" == "true" ]]; then
        # Compute IMAGE_NAME for rebuild
        local project_folder_name
        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
        IMAGE_NAME="claudebox-${project_folder_name}"
        warn "Rebuilding ClaudeBox Docker image..."
        if docker image inspect "$IMAGE_NAME" &>/dev/null; then
            docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
            docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
        fi
        set -- "${new_args[@]}"
    fi

    # Compute project folder name early
    local project_folder_name
        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
        IMAGE_NAME="claudebox-${project_folder_name}"
    project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
    IMAGE_NAME="claudebox-${project_folder_name}"
    PROJECT_CLAUDEBOX_DIR="$HOME/.claudebox/$project_folder_name"
    
    # Ensure project directory exists
    mkdir -p "$PROJECT_CLAUDEBOX_DIR"

    # Handle help immediately
    if [[ "$found_help" == "true" ]]; then
        if docker image inspect "$IMAGE_NAME" &>/dev/null; then
            docker run --rm \
                -u "$DOCKER_USER" \
                --entrypoint /home/$DOCKER_USER/claude-wrapper \
                "$IMAGE_NAME" --help | sed '1s/claude/claudebox/g'
            echo
            cecho "Added Options:" "$WHITE"
            echo -e "${CYAN}  --verbose                       ${WHITE}Show detailed output"
            echo -e "${CYAN}  --enable-sudo                   ${WHITE}Enable sudo without password"
            echo -e "${CYAN}  --disable-firewall              ${WHITE}Disable network restrictions"
            echo
            cecho "Added Commands:" "$WHITE"
            echo -e "  profile [names...]              Install language profiles"
            echo -e "  install <packages>              Install apt packages"
            echo -e "  save [flags...]                 Save default flags (no args = clear saved flags)"
            echo -e "  shell                           Open bash shell in container"
            echo -e "  info                            Show profiles, saved CLI flags, and container status"
            echo -e "  clean                           Menu of cleanup tasks"
            echo -e "  unlink                          Remove claudebox symlink"
            echo -e "  rebuild                         Rebuild the Docker image from scratch${NC}"
        else
            cecho "ClaudeBox - Claude Code Docker Environment" "$CYAN"
            echo
            warn "First run setup required!"
            echo "Run script without arguments first to build the Docker image."
        fi
        exit 0
    fi

    # Handle commands
    [[ "$VERBOSE" == "true" ]] && echo "Command: ${1:-none}" >&2
    case "${1:-}" in
        profile)
            shift
            if [[ $# -eq 0 ]]; then
                cecho "Available Profiles:" "$CYAN"
                echo
                for profile in $(printf '%s\n' "${!PROFILE_DESCRIPTIONS[@]}" | sort); do
                    echo -e "  ${GREEN}$profile${NC} - ${PROFILE_DESCRIPTIONS[$profile]}"
                done
                echo
                warn "Usage: claudebox profile <name> [<name2> ...]"
                warn "Example: claudebox profile c python web"
                exit 0
            fi

            local selected=() remaining=()
            while [[ $# -gt 0 ]]; do
                # accept profiles even if the value is empty
                # check that the key exists in the PROFILES associative array
                if [[ -v PROFILES[$1] ]]; then
                    selected+=("$1")
                    shift
                else
                    remaining=("$@")
                    break
                fi
            done

            [[ ${#selected[@]} -eq 0 ]] && error "No valid profiles specified\nRun 'claudebox profile' to see available profiles"

            local profile_file
            profile_file=$(get_profile_file_path)

            # Update profiles section
            update_profile_section "$profile_file" "profiles" "${selected[@]}"

            # Read all current profiles for display
            local all_profiles=()
            readarray -t all_profiles < <(read_profile_section "$profile_file" "profiles")

            cecho "Profile: $PROJECT_DIR" "$CYAN"
            cecho "Installing profiles: ${selected[*]}" "$PURPLE"
            if [[ ${#all_profiles[@]} -gt 0 ]]; then
                cecho "All active profiles: ${all_profiles[*]}" "$GREEN"
            fi
            echo

            # Continue to main execution to create container with profiles
            if [[ ${#remaining[@]} -gt 0 ]]; then
                set -- "${remaining[@]}"
            fi
            ;;
        save)
            shift
            defaults_file="$HOME/.claudebox/default-flags"

            if [[ $# -eq 0 ]]; then
                if [[ -f "$defaults_file" ]]; then
                    rm -f "$defaults_file"
                    success "Cleared saved default flags"
                else
                    info "No saved default flags to clear"
                fi
            else
                mkdir -p "$HOME/.claudebox"
                printf '%s\n' "$@" > "$defaults_file"
                success "Saved default flags: $*"
            fi
            exit 0
                        ;;
        install)
            shift
            [[ $# -eq 0 ]] && error "No packages specified. Usage: claudebox install <package1> <package2> ..."

            local profile_file
            profile_file=$(get_profile_file_path)

            # Update packages section
            update_profile_section "$profile_file" "packages" "$@"

            # Read all current packages for display
            local all_packages=()
            readarray -t all_packages < <(read_profile_section "$profile_file" "packages")

            cecho "Profile: $PROJECT_DIR" "$CYAN"
            cecho "Installing packages: $*" "$PURPLE"
            if [[ ${#all_packages[@]} -gt 0 ]]; then
                cecho "All packages: ${all_packages[*]}" "$GREEN"
            fi
            echo
            ;;
        
        unlink)
            if [[ -L "$LINK_TARGET" ]]; then
                rm -f "$LINK_TARGET"
                success "Removed claudebox symlink from $(dirname "$LINK_TARGET")"
            else
                info "No claudebox symlink found at $LINK_TARGET"
            fi
            exit 0
            ;;


        update|config|mcp|migrate-installer)
            [[ ! -f /.dockerenv ]] && docker image inspect "$IMAGE_NAME" &>/dev/null || \
                error "ClaudeBox image not found.\nRun ${GREEN}claudebox${NC} first to build the image."
                        local project_folder_name
                        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
                        IMAGE_NAME="claudebox-${project_folder_name}"
            local cmd=$1
            shift

            info "Running $cmd command..."

            # Create temporary container
            local temp_container="claudebox-temp-${project_folder_name}-$$"
            docker run -d --name "$temp_container" \
                -v "$PROJECT_DIR":/workspace \
                -v "$HOME/.claudebox/$project_folder_name":/home/$DOCKER_USER \
                -v "$HOME/.claudebox":/home/$DOCKER_USER/.claudebox:ro \
                -e "CLAUDEBOX_PROJECT_NAME=$project_folder_name" \
                "$IMAGE_NAME" --shell-mode >/dev/null

            if [[ "$cmd" == "update" ]]; then
                info "Updating Claude code..."
                docker exec -u "$DOCKER_USER" "$temp_container" bash -c "
                    source \$HOME/.nvm/nvm.sh
                    nvm use default
                    claude update
                    claude --version
                "
            else
                docker exec -it -u "$DOCKER_USER" "$temp_container" \
                    ~/claude-wrapper "${DEFAULT_FLAGS[@]}" "$cmd" "$@"
            fi

            # Commit changes back to image
            docker commit "$temp_container" "$IMAGE_NAME" >/dev/null
            docker stop "$temp_container" 2>/dev/null || true >/dev/null
            docker rm "$temp_container" 2>/dev/null || true

            success "$cmd completed and saved to image!"
            exit 0
            ;;

        shell)
            shift
            # Just add --shell-mode to the arguments and continue
            set -- "--shell-mode" "$@"
            ;;

        clean)
            shift
            case "${1:-}" in
                --all|-a)
                    warn "Complete Docker cleanup: removing all claudebox containers, images, volumes, and cache..."
                    # Remove all claudebox containers
                    docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
                    docker ps -a --format "{{.Names}}" | grep "^claudebox-" | xargs -r docker rm -f 2>/dev/null || true
                    
                    # Remove ALL claudebox images (including base)
                    docker images --filter "reference=claudebox-*" -q | xargs -r docker rmi -f 2>/dev/null || true
                    docker images --filter "reference=claudebox" -q | xargs -r docker rmi -f 2>/dev/null || true
                    
                    # Remove dangling images
                    docker images -f "dangling=true" -q | xargs -r docker rmi -f 2>/dev/null || true
                    
                    # Prune build cache
                    docker builder prune -af 2>/dev/null || true
                    
                    # Remove volumes
                    docker volume ls -q --filter "name=claudebox" | xargs -r docker volume rm 2>/dev/null || true
                    
                    success "Docker cleanup complete!"
                    ;;
                --image|-i)
                    warn "Removing ClaudeBox containers and image..."
                    # Remove any containers from this image
                    docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
                    # Remove orphaned containers from images that no longer exist
                    # This is safer as it only removes containers whose images are gone
                    docker ps -a --filter "status=exited" --format "{{.ID}} {{.Image}}" | while read id image; do
                        if ! docker image inspect "$image" >/dev/null 2>&1; then
                            docker rm -f "$id" 2>/dev/null || true
                        fi
                    done
                   # Remove all claudebox project images
                   docker images --filter "reference=claudebox-*" -q | xargs -r docker rmi -f 2>/dev/null || true
                    docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
                    success "Containers and image removed! Build cache preserved."
                    ;;
                --cache|-c)
                    warn "Cleaning Docker build cache..."
                    docker builder prune -af
                    success "Build cache cleaned!"
                    ;;
                --volumes|-v)
                    warn "Removing ClaudeBox-related volumes..."
                    docker volume ls -q --filter "name=claudebox" | xargs -r docker volume rm 2>/dev/null || true
                    docker volume prune -f 2>/dev/null || true
                    success "Volumes cleaned!"
                    ;;
                --containers|-c)
                    warn "Cleaning ClaudeBox containers..."
                    # Remove any containers from this image
                    docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
                    # Remove orphaned containers from images that no longer exist
                    # This is safer as it only removes containers whose images are gone
                    docker ps -a --filter "status=exited" --format "{{.ID}} {{.Image}}" | while read id image; do
                        if ! docker image inspect "$image" >/dev/null 2>&1; then
                            docker rm -f "$id" 2>/dev/null || true
                        fi
                    done
                    success "Containers cleaned!"
                    ;;
                --dangling|-d)
                    warn "Removing dangling images and unused containers..."
                    docker image prune -f
                    docker container prune -f
                    success "Dangling resources cleaned!"
                    ;;
                --logs|-l)
                    warn "Clearing Docker container logs..."
                    docker ps -a --filter "label=claudebox.project" -q | while read -r container; do
                        docker logs "$container" >/dev/null 2>&1 && echo -n | docker logs "$container" 2>/dev/null || true
                    done
                    success "Container logs cleared!"
                    ;;
                --project|-p)
                    shift
                    local project_folder_name
                    project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
                    local project_claudebox_dir="$HOME/.claudebox/$project_folder_name"
                    local image_name="claudebox-${project_folder_name}"
                    local profile_file
                    profile_file=$(get_profile_file_path)
                    
                    case "${1:-}" in
                        tools)
                            warn "Removing profile configuration for: $PROJECT_DIR"
                            if [[ -f "$profile_file" ]]; then
                                rm -f "$profile_file"
                                success "Removed profile configuration"
                            else
                                info "No profile configuration found"
                            fi
                            ;;
                        data)
                            warn "Removing project data for: $PROJECT_DIR"
                            if [[ -d "$project_claudebox_dir" ]]; then
                                rm -rf "$project_claudebox_dir"
                                success "Removed project data folder: $project_claudebox_dir"
                            else
                                info "No project data folder found"
                            fi
                            ;;
                        docker)
                            warn "Removing Docker image for: $PROJECT_DIR"
                            docker rmi -f "$image_name" 2>/dev/null && \
                                success "Removed Docker image: $image_name" || \
                                info "No Docker image found for this project"
                            ;;
                        all)
                            warn "Removing all project artifacts for: $PROJECT_DIR"
                            # Remove profile
                            if [[ -f "$profile_file" ]]; then
                                rm -f "$profile_file"
                                success "Removed profile configuration"
                            fi
                            # Remove data
                            if [[ -d "$project_claudebox_dir" ]]; then
                                rm -rf "$project_claudebox_dir"
                                success "Removed project data folder"
                            fi
                            # Remove Docker image
                            docker rmi -f "$image_name" 2>/dev/null && \
                                success "Removed Docker image" || \
                                info "No Docker image found"
                            ;;
                        *)
                            # Show project cleanup submenu
                            cecho "ClaudeBox Project Clean Options:" "$CYAN"
                            echo
                            echo -e "  ${GREEN}clean --project tools${NC}    Remove profile configuration (*.ini file)"
                            echo -e "  ${GREEN}clean --project data${NC}     Remove all project data (home directory)"
                            echo -e "  ${GREEN}clean --project docker${NC}   Remove project Docker image and layers"
                            echo -e "  ${GREEN}clean --project all${NC}      Remove everything for this project"
                            echo
                            cecho "Current project: $PROJECT_DIR" "$YELLOW"
                            exit 0
                            ;;
                    esac
                    exit 0
                    ;;
                *)
                    # Show menu by default
                    cecho "ClaudeBox Clean Options:" "$CYAN"
                    echo
                    echo -e "  ${GREEN}clean --containers${NC}       Remove all containers (preserves image)"
                    echo -e "  ${GREEN}clean --project${NC}          Show project cleanup options"
                    echo -e "  ${GREEN}clean --all${NC}              Remove all Docker artifacts (containers, images, cache, volumes)"
                    echo -e "  ${GREEN}clean --image${NC}            Remove containers and image (preserves build cache)"
                    echo -e "  ${GREEN}clean --cache${NC}            Remove Docker build cache only"
                    echo -e "  ${GREEN}clean --volumes${NC}          Remove associated Docker volumes"
                    echo -e "  ${GREEN}clean --dangling${NC}         Remove dangling images and unused containers"
                    echo -e "  ${GREEN}clean --logs${NC}             Clear Docker container logs"
                    echo
                    cecho "Examples:" "$YELLOW"
                    echo "  claudebox clean --containers # Remove all containers"
                    echo "  claudebox clean --project    # Show project cleanup menu"
                    echo "  claudebox clean --image      # Remove containers and image"
                    echo "  claudebox clean --all        # Complete Docker cleanup"
                    exit 0
                    ;;
            esac
            echo
            docker system df
            exit 0
            ;;

        help|--help|-h)
            if docker image inspect "$IMAGE_NAME" &>/dev/null; then
                docker run --rm \
                    -u "$DOCKER_USER" \
                    --entrypoint /home/$DOCKER_USER/claude-wrapper \
                    "$IMAGE_NAME" --help | sed '1s/claude/claudebox/g'
                echo
                cecho "Added Options:" "$WHITE"
                echo -e "${CYAN}  --verbose                       ${WHITE}Show detailed output"
                echo -e "${CYAN}  --enable-sudo                   ${WHITE}Enable sudo without password"
                echo -e "${CYAN}  --disable-firewall              ${WHITE}Disable network restrictions"
                echo
                cecho "Added Commands:" "$WHITE"
                echo -e "  profile [names...]              Install language profiles"
                echo -e "  install <packages>              Install apt packages"
                echo -e "  save [flags...]                 Save default flags (no args = clear saved flags)"
                echo -e "  shell                           Open bash shell in container"
                echo -e "  info                            Show profiles, saved CLI flags, and container status"
                echo -e "  clean                           Menu of cleanup tasks"
                echo -e "  unlink                          Remove claudebox symlink"
                echo -e "  rebuild                         Rebuild the Docker image from scratch${NC}"
            else
                cecho "ClaudeBox - Claude Code Docker Environment" "$CYAN"
                echo
                warn "First run setup required!"
                echo "Run script without arguments first to build the Docker image."
            fi
            exit 0
            ;;

        info)
            shift
            cecho "ClaudeBox Profile Status" "$CYAN"
            echo

            local profile_dir="$HOME/.claudebox/profiles"
            if [[ ! -d "$profile_dir" ]] || [[ -z "$(ls -A "$profile_dir" 2>/dev/null)" ]]; then
                warn "No profiles configured yet."
                exit 0
            fi

            # Show all profiles
            local count
            count=$(ls -1 "$profile_dir"/*.ini 2>/dev/null | wc -l)
            info "Tracking $count project profile(s)"
            echo

            # Show each project's profiles
            for pfile in "$profile_dir"/*.ini; do
                [[ -f "$pfile" ]] || continue
                local proj_path
                proj_path=$(basename "$pfile" .ini | sed 's|-|/|g')
                cecho "/$proj_path:" "$YELLOW"

                # Show profiles
                local profiles=()
                readarray -t profiles < <(read_profile_section "$pfile" "profiles")
                if [[ ${#profiles[@]} -gt 0 ]]; then
                    echo "  Profiles: ${profiles[*]}"
                fi

                # Show packages
                local packages=()
                readarray -t packages < <(read_profile_section "$pfile" "packages")
                if [[ ${#packages[@]} -gt 0 ]]; then
                    echo "  Packages: ${packages[*]}"
                fi
                echo
            done

            # Show current project's profiles
            local current_profile_file
            current_profile_file=$(get_profile_file_path)
            if [[ -f "$current_profile_file" ]]; then
                cecho "Current project ($PROJECT_DIR):" "$GREEN"
                local current_profiles=()
                readarray -t current_profiles < <(read_profile_section "$current_profile_file" "profiles")
                if [[ ${#current_profiles[@]} -gt 0 ]]; then
                    echo "  Profiles: ${current_profiles[*]}"
                fi

                local current_packages=()
                readarray -t current_packages < <(read_profile_section "$current_profile_file" "packages")
                if [[ ${#current_packages[@]} -gt 0 ]]; then
                    echo "  Packages: ${current_packages[*]}"
                fi
            else
                info "Current project has no profiles configured."
            fi

            # Show saved CLI flags
            echo
            if [[ -f "$HOME/.claudebox/default-flags" ]]; then
                cecho "Saved Claude CLI flags:" "$CYAN"
                local saved_flags=()
                while IFS= read -r flag; do
                    [[ -n "$flag" ]] && saved_flags+=("$flag")
                done < "$HOME/.claudebox/default-flags"
                if [[ ${#saved_flags[@]} -gt 0 ]]; then
                    echo "  ${saved_flags[*]}"
                else
                    echo "  (empty)"
                fi
            else
                info "No saved Claude CLI flags"
            fi

            # Show running containers
            echo
            local running_containers
            running_containers=$(docker ps --filter "ancestor=$IMAGE_NAME" --format "table {{.ID}}\t{{.Status}}\t{{.Command}}" | tail -n +2)
            if [[ -n "$running_containers" ]]; then
                cecho "Running ClaudeBox containers:" "$YELLOW"
                echo "$running_containers"
            else
                info "No ClaudeBox containers currently running."
            fi

            # Show all ClaudeBox images
            echo
            local claudebox_images
            claudebox_images=$(docker images --filter "reference=claudebox-*" --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | tail -n +1)
            if [[ -n "$claudebox_images" ]]; then
                cecho "ClaudeBox Docker Images:" "$YELLOW"
                echo "$claudebox_images"
            fi


            exit 0
            ;;

    esac

    # Setup workspace and global config
    setup_project_folder
    setup_claude_agent_command

    # Profile tracking
    mkdir -p "$HOME/.claudebox/profiles"

    # Check if we need to rebuild based on profiles
    local need_rebuild=false
    local current_profiles=()
    local profile_hash=""

    # Read profiles for current project only
    if [[ -d "$HOME/.claudebox/profiles" ]]; then
        for profile_file in "$HOME/.claudebox/profiles"/*.ini; do
            [[ -f "$profile_file" ]] || continue
            local profiles_from_file=()
            readarray -t profiles_from_file < <(read_profile_section "$profile_file" "profiles")
            for profile in "${profiles_from_file[@]}"; do
                profile=$(echo "$profile" | tr -d '[:space:]')
                [[ -z "$profile" ]] && continue
                # Add to array if not already present
                local found=false
                for p in "${current_profiles[@]}"; do
                    [[ "$p" == "$profile" ]] && found=true && break
                                done
                [[ "$found" == "false" ]] && current_profiles+=("$profile")
            done
        done

        if [[ ${#current_profiles[@]} -gt 0 ]]; then
            profile_hash=$(printf '%s\n' "${current_profiles[@]}" | sort | sha256sum | cut -d' ' -f1)
        fi
    fi

    # Check if image exists and if profiles match
    if docker image inspect "$IMAGE_NAME" >/dev/null 2>&1; then
        # Get the profile hash from the image labels
        local image_profile_hash
        image_profile_hash=$(docker inspect "$IMAGE_NAME" --format '{{index .Config.Labels "claudebox.profiles"}}' 2>/dev/null || echo "")

        if [[ "$profile_hash" != "$image_profile_hash" ]]; then
            warn "Profiles have changed. Rebuilding image..."
            warn "Current profiles: ${current_profiles[*]}"
            docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
            need_rebuild=true
        fi
    else
        need_rebuild=true
    fi

        # Build image if needed
        if [[ "$need_rebuild" == "true" ]] || ! docker image inspect "$IMAGE_NAME" >/dev/null 2>&1; then
                logo
                local build_context="$HOME/.claudebox/build"
                mkdir -p "$build_context"
                local dockerfile="$build_context/Dockerfile"

        create_build_files "$build_context"

    info "Using git-delta version: $DELTA_VERSION"

        cat > "$dockerfile" <<'DOCKERFILE'
FROM debian:bookworm
ARG USER_ID GROUP_ID USERNAME NODE_VERSION DELTA_VERSION

RUN echo '#!/bin/sh\nexit 101' > /usr/sbin/policy-rc.d && chmod +x /usr/sbin/policy-rc.d

# Install locales first to fix locale warnings
RUN export DEBIAN_FRONTEND=noninteractive && \
    apt-get update && \
        apt-get install -y --no-autoremove --no-install-recommends ca-certificates curl locales gnupg && apt-get clean && \
    echo "en_US.UTF-8 UTF-8" > /etc/locale.gen && locale-gen en_US.UTF-8 &&\
        mkdir -p /usr/share/keyrings && \
        curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg -o /tmp/githubcli.gpg && \
        cat /tmp/githubcli.gpg | gpg --dearmor -o /usr/share/keyrings/githubcli-archive-keyring.gpg && \
        rm -f /tmp/githubcli.gpg && \
    chmod 644 /usr/share/keyrings/githubcli-archive-keyring.gpg && \
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg]" \
    "https://cli.github.com/packages stable main" | tee /etc/apt/sources.list.d/github-cli.list > /dev/null && apt-get update && \
        apt-get install -y --no-autoremove --no-install-recommends apt-utils wget zsh fzf ca-certificates sudo git iptables ipset gh unzip jq \
        procps vim nano less && \
        rm -rf /var/lib/apt/lists/*

# Set locale environment variables
ENV LANG=en_US.UTF-8 \
    LANGUAGE=en_US:en \
    LC_ALL=en_US.UTF-8

RUN groupadd -g $GROUP_ID $USERNAME || true && \
    useradd -m -u $USER_ID -g $GROUP_ID -s /bin/bash $USERNAME

RUN ARCH=$(dpkg --print-architecture) && \
    wget -q https://github.com/dandavison/delta/releases/download/${DELTA_VERSION}/git-delta_${DELTA_VERSION}_${ARCH}.deb && \
    dpkg -i git-delta_${DELTA_VERSION}_${ARCH}.deb && \
    rm git-delta_${DELTA_VERSION}_${ARCH}.deb

USER $USERNAME
WORKDIR /home/$USERNAME

RUN sh -c "$(wget -O- https://github.com/deluan/zsh-in-docker/releases/download/v1.2.0/zsh-in-docker.sh)" -- \
    -p git \
    -p fzf \
    -a "source /usr/share/doc/fzf/examples/key-bindings.zsh" \
    -a "source /usr/share/doc/fzf/examples/completion.zsh" \
    -a 'export HISTFILE="/home/$USERNAME/.zsh_history"' \
    -a 'export HISTSIZE=10000' \
    -a 'export SAVEHIST=10000' \
    -a 'setopt HIST_IGNORE_DUPS' \
    -a 'setopt SHARE_HISTORY' \
    -a 'export NVM_DIR="$HOME/.nvm"' \
    -a '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' \
    -a '[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"' \
    -x

RUN curl -LsSf https://astral.sh/uv/install.sh | sh

RUN echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc && \
    echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.zshrc

RUN git config --global core.pager delta && \
    git config --global interactive.diffFilter "delta --color-only" && \
    git config --global delta.navigate true && \
    git config --global delta.light false && \
    git config --global delta.side-by-side true

# Set DEVCONTAINER environment variable to help with orientation
ENV DEVCONTAINER=true

# Set the default shell to zsh rather than sh
ENV SHELL=/bin/zsh

ENV NVM_DIR="/home/$USERNAME/.nvm"
RUN curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash

RUN bash -c "source $NVM_DIR/nvm.sh && \
    if [[ \"$NODE_VERSION\" == '--lts' ]]; then \
        nvm install --lts && \
        nvm alias default 'lts/*'; \
    else \
        nvm install $NODE_VERSION && \
        nvm alias default $NODE_VERSION; \
    fi && \
    nvm use default"

RUN echo 'export NVM_DIR="$HOME/.nvm"' >> ~/.bashrc && \
    echo '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' >> ~/.bashrc && \
    echo '[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"' >> ~/.bashrc

RUN bash -c "source $NVM_DIR/nvm.sh && \
    nvm use default && \
    npm install -g @anthropic-ai/claude-code"


# Install profile packages as separate layers for better caching
USER root
DOCKERFILE
        if [[ ${#current_profiles[@]} -gt 0 ]]; then
                info "Building with profiles: ${current_profiles[*]}"

                # Resolve and deduplicate all dependency layers
                resolved_profiles=()
                for profile in "${current_profiles[@]}"; do
                        resolved_profiles+=($(expand_profile "$profile"))
                done

                unique_profiles=($(awk -v RS=' ' '!seen[$1]++' <<< "${resolved_profiles[*]}"))

                # APT install layers (1 per profile)
                for profile in "${unique_profiles[@]}"; do
                        pkg_list=(${PROFILES[$profile]:-})
                        [[ ${#pkg_list[@]} -eq 0 ]] && continue

        cat >> "$dockerfile" <<DOCKERFILE
# ${PROFILE_DESCRIPTIONS[$profile]}
RUN export DEBIAN_FRONTEND=noninteractive && \\
        apt-get update && \\
        apt-get install -y --no-autoremove ${pkg_list[*]} && \\
        apt-get clean && rm -rf /var/lib/apt/lists/*
DOCKERFILE
                                case "$profile" in
                                        rust)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y && \
        echo 'source $HOME/.cargo/env' >> ~/.bashrc && \
        echo 'source $HOME/.cargo/env' >> ~/.zshrc
USER root
DOCKERFILE
                                                ;;
                                        go)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
RUN GO_VERSION="1.21.5" && \
        wget -q "https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz" && \
        tar -C /usr/local -xzf "go${GO_VERSION}.linux-amd64.tar.gz" && \
        rm "go${GO_VERSION}.linux-amd64.tar.gz" && \
        echo 'export PATH=$PATH:/usr/local/go/bin' >> /etc/profile.d/go.sh
DOCKERFILE
                                                ;;
                                        python)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN ~/.local/bin/uv pip install ipython black mypy pylint pytest ruff poetry pipenv
USER root
DOCKERFILE
                                                ;;
                                        ml)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN ~/.local/bin/uv pip install torch transformers scikit-learn numpy pandas matplotlib
USER root
DOCKERFILE
                                                ;;
                                        datascience)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN ~/.local/bin/uv pip install jupyter notebook jupyterlab numpy pandas scipy matplotlib seaborn scikit-learn statsmodels plotly
USER root
DOCKERFILE
                                                ;;
                                        javascript)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN bash -c "source \$NVM_DIR/nvm.sh && npm install -g typescript eslint prettier yarn pnpm"
USER root
DOCKERFILE
                                                ;;
                                        *) : ;;
                                esac
                        done
                fi

        # Add label with profile hash
        echo "# Label the image with the profile hash for change detection" >> "$dockerfile"
        echo "LABEL claudebox.profiles=\"$profile_hash\"" >> "$dockerfile"
        echo "LABEL claudebox.project=\"$project_folder_name\"" >> "$dockerfile"
        echo "" >> "$dockerfile"
        cat >> "$dockerfile" <<'DOCKERFILE'

# Copy internal scripts to home directory
COPY --chmod=755 claude-wrapper /home/$USERNAME/claude-wrapper
COPY --chmod=755 init-firewall /home/$USERNAME/init-firewall
RUN chown $USERNAME:$USERNAME /home/$USERNAME/claude-wrapper /home/$USERNAME/init-firewall

USER $USERNAME
RUN bash -c "source $NVM_DIR/nvm.sh && claude --version"

WORKDIR /workspace
USER root
COPY --chown=$USERNAME docker-entrypoint.sh /usr/local/bin/docker-entrypoint
RUN sed -i "s/DOCKERUSER/$USERNAME/g" /usr/local/bin/docker-entrypoint && \
    sed -i "s/DOCKERUSER/$USERNAME/g" /home/$USERNAME/init-firewall && \
    chmod +x /usr/local/bin/docker-entrypoint

ENTRYPOINT ["/usr/local/bin/docker-entrypoint"]
DOCKERFILE

        run_docker_build "$dockerfile" "$build_context"

        echo -e "\n${GREEN}Complete!${NC}\n"
        success "Docker image '$IMAGE_NAME' built!"

        echo
        cecho "ClaudeBox Setup Complete!" "$CYAN"
        echo
        cecho "Quick Start:" "$GREEN"
        echo -e "  ${YELLOW}claudebox [options]${NC}        # Launch Claude CLI"
        echo
        cecho "Power Features:" "$GREEN"
        echo -e "  ${YELLOW}claudebox profile${NC}                # See all language profiles"
        echo -e "  ${YELLOW}claudebox profile c openwrt${NC}      # Install C + OpenWRT tools"
        echo -e "  ${YELLOW}claudebox profile python ml${NC}      # Install Python + ML stack"
        echo -e "  ${YELLOW}claudebox install <packages>${NC}     # Install additional apt packages"
        echo -e "  ${YELLOW}claudebox shell${NC}                  # Open bash shell in container"
        echo
        cecho "Security:" "$GREEN"
        echo -e "  Network firewall: ON by default (Anthropic recommended)"
        echo -e "  Sudo access: OFF by default"
        echo
        cecho "Maintenance:" "$GREEN"
        echo -e "  ${YELLOW}claudebox clean ${NC}                 # See all cleanup options"
        echo -e "  ${YELLOW}claudebox unlink ${NC}                # Remove symbolic link"
        echo
        cecho "Just install the profile you need and start coding!" "$PURPLE"
       exit 0
   fi

   # Run container
   local extra_mounts=()

   # Ensure .claudebox exists with proper permissions
   if [[ ! -d "$HOME/.claudebox" ]]; then
       mkdir -p "$HOME/.claudebox"
   fi

   # Fix permissions if needed
   if [[ ! -w "$HOME/.claudebox" ]]; then
       warn "Fixing .claudebox permissions..."
       sudo chown -R "$USER:$USER" "$HOME/.claudebox" || true
   fi

   # Create project-specific allowlist if it doesn't exist
   local allowlist_file="$PROJECT_CLAUDEBOX_DIR/firewall/allowlist"

   if [[ ! -f "$allowlist_file" ]]; then
       mkdir -p "$(dirname "$allowlist_file")"
       info "Creating default firewall allowlist for project..."
       cat > "$allowlist_file" <<'EOF'
# ClaudeBox Firewall Allowlist
# Lines starting with # are comments
# Add one domain or IP range per line
#
# Default domains (always allowed):
# - api.anthropic.com
# - console.anthropic.com
# - statsig.anthropic.com
# - sentry.io

# ====================
# GitHub.com
# ====================
github.com
api.github.com
raw.githubusercontent.com
ssh.github.com
avatars.githubusercontent.com
codeload.github.com
objects.githubusercontent.com
pipelines.actions.githubusercontent.com
ghcr.io
pkg-containers.githubusercontent.com

# ====================
# GitLab.com
# ====================
gitlab.com
api.gitlab.com
registry.gitlab.com
uploads.gitlab.com
gitlab.io
*.gitlab.io
*.s3.amazonaws.com
*.amazonaws.com

# ====================
# Bitbucket.org
# ====================
bitbucket.org
api.bitbucket.org
altssh.bitbucket.org
bbuseruploads.s3.amazonaws.com
bitbucket-pipelines-prod-us-west-2.s3.amazonaws.com
bitbucket-pipelines-prod-us-east-1.s3.amazonaws.com
bitbucket-pipelines-prod-eu-west-1.s3.amazonaws.com

# ====================
# Atlassian IP Ranges (Bitbucket Cloud)
# ====================
104.192.136.0/21
185.166.140.0/22
13.200.41.128/25
18.246.31.128/25

# ====================
# Optional (Git LFS, Assets)
# ====================
github-cloud.s3.amazonaws.com
github-releases.githubusercontent.com
github-production-release-asset-2e65be.s3.amazonaws.com
EOF
       success "Created default allowlist"
   fi

   set -- "${DEFAULT_FLAGS[@]}" "$@"

   # Build Docker arguments
   local docker_args=()
   [[ "$ENABLE_SUDO" == "true" ]] && docker_args+=("--enable-sudo")
   [[ "$DISABLE_FIREWALL" == "true" ]] && docker_args+=("--disable-firewall")

   docker run -it --rm --init \
       -w /workspace \
       -v "$PROJECT_DIR":/workspace \
       -v "$PROJECT_CLAUDEBOX_DIR/.claude":/home/$DOCKER_USER/.claude \
       -v "$PROJECT_CLAUDEBOX_DIR/.claude.json":/home/$DOCKER_USER/.claude.json \
       -v "$PROJECT_CLAUDEBOX_DIR/.zsh_history":/home/$DOCKER_USER/.zsh_history \
       -v "$PROJECT_CLAUDEBOX_DIR/.config":/home/$DOCKER_USER/.config \
       -v "$HOME/.ssh":/home/$DOCKER_USER/.ssh:ro \
       -e "NODE_ENV=${NODE_ENV:-production}" \
       -e "ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}" \
       -e "CLAUDEBOX_PROJECT_NAME=$project_folder_name" \
       --cap-add NET_ADMIN \
       --cap-add NET_RAW \
       "$IMAGE_NAME" "${docker_args[@]}" "$@"
}

main "$@"
