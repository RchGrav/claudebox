#!/bin/bash
set -euo pipefail
if [ "${DISABLE_FIREWALL:-false}" = "true" ]; then
    echo "Firewall disabled, skipping setup"
    rm -f "$0"
    exit 0
fi
iptables -F OUTPUT 2>/dev/null || true
iptables -F INPUT 2>/dev/null || true
iptables -A OUTPUT -p udp --dport 53 -j ACCEPT
iptables -A OUTPUT -p tcp --dport 53 -j ACCEPT
iptables -A INPUT -p udp --sport 53 -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT
iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -s 127.0.0.0/8 -d 127.0.0.0/8 -j ACCEPT
iptables -A INPUT -s 127.0.0.0/8 -d 127.0.0.0/8 -j ACCEPT
iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
# Default allowed domains
DEFAULT_DOMAINS="api.anthropic.com console.anthropic.com statsig.anthropic.com sentry.io"

# Read additional domains from allowlist file if it exists
ALLOWED_DOMAINS="$DEFAULT_DOMAINS"
# Try project-specific allowlist first, then fall back to global
if [ -f /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/firewall/allowlist ]; then
    while IFS= read -r domain; do
        # Skip comments and empty lines
        [[ "$domain" =~ ^#.* ]] && continue
        [[ -z "$domain" ]] && continue
        # Remove wildcards for now (*.example.com becomes example.com)
        domain="${domain#\*.}"
        ALLOWED_DOMAINS="$ALLOWED_DOMAINS $domain"
    done < /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/firewall/allowlist
elif [ -f /home/DOCKERUSER/.claudebox/allowlist ]; then
    while IFS= read -r domain; do
        # Skip comments and empty lines
        [[ "$domain" =~ ^#.* ]] && continue
        [[ -z "$domain" ]] && continue
        # Remove wildcards for now (*.example.com becomes example.com)
        domain="${domain#\*.}"
        ALLOWED_DOMAINS="$ALLOWED_DOMAINS $domain"
    done < /home/DOCKERUSER/.claudebox/allowlist
fi

if command -v ipset >/dev/null 2>&1; then
    ipset destroy allowed-domains 2>/dev/null || true
    ipset create allowed-domains hash:net
    ipset destroy allowed-ips 2>/dev/null || true
    ipset create allowed-ips hash:net

    for domain in $ALLOWED_DOMAINS; do
        # Check if it's an IP range
        if [[ "$domain" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/[0-9]+$ ]]; then
            ipset add allowed-ips $domain 2>/dev/null || true
        else
            # It's a domain, resolve it
            ips=$(getent hosts $domain 2>/dev/null | awk '{print $1}')
            for ip in $ips; do
                ipset add allowed-domains $ip 2>/dev/null || true
            done
        fi
    done
    iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
    iptables -A OUTPUT -m set --match-set allowed-ips dst -j ACCEPT
else
    # Fallback without ipset
    for domain in $ALLOWED_DOMAINS; do
        if [[ "$domain" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/[0-9]+$ ]]; then
            iptables -A OUTPUT -d $domain -j ACCEPT
        else
            # Resolve domain to IPs
            ips=$(getent hosts $domain 2>/dev/null | awk '{print $1}')
            for ip in $ips; do
                iptables -A OUTPUT -d $ip -j ACCEPT
            done
        fi
    done
fi
iptables -P OUTPUT DROP
iptables -P INPUT DROP
echo "Firewall initialized with Anthropic-only access"
rm -f "$(realpath "$0")"
EOF

    cat > "$build_context/claude-wrapper" << 'EOF'
#!/bin/bash
set -euo pipefail

export NVM_DIR="$HOME/.nvm"

# Check if nvm exists before sourcing
if [[ -s "$NVM_DIR/nvm.sh" ]]; then
    \. "$NVM_DIR/nvm.sh"
    nvm use default >/dev/null 2>&1 || {
        echo "Warning: Failed to activate default Node version" >&2
    }
else
    echo "Warning: NVM not found at $NVM_DIR" >&2
fi
rm -f "$(realpath "$0")"
# Execute claude with all arguments
exec claude "$@"
EOF

    cat > "$build_context/docker-entrypoint.sh" << 'EOF'
#!/bin/bash
set -euo pipefail
ENABLE_SUDO=false
DISABLE_FIREWALL=false
new_args=()
while [[ $# -gt 0 ]]; do
    case "$1" in
        --enable-sudo) ENABLE_SUDO=true; shift ;;
        --disable-firewall) DISABLE_FIREWALL=true; shift ;;
        *) new_args+=("$1"); shift ;;
    esac
done
set -- "${new_args[@]}"
export DISABLE_FIREWALL

# Set up project-specific symlinks
if [ -d /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME ]; then
    # Ensure memory directory is accessible
    mkdir -p /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/memory
    chown -R DOCKERUSER:DOCKERUSER /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME
fi

# Handle project-specific .claude.json
if [ -d /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME ]; then
    # If this is the first run for this project and no project-specific .claude.json exists
    if [ ! -f /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.claude.json ] && [ -f /home/DOCKERUSER/.claude.json.host ]; then
        # Copy the host's .claude.json as a starting point
        cp /home/DOCKERUSER/.claude.json.host /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.claude.json
        chown DOCKERUSER:DOCKERUSER /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.claude.json
    fi

    # If project-specific .claude.json exists, symlink it
    if [ -f /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.claude.json ]; then
        rm -f /home/DOCKERUSER/.claude.json
        ln -s /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.claude.json /home/DOCKERUSER/.claude.json
        chown -h DOCKERUSER:DOCKERUSER /home/DOCKERUSER/.claude.json
    fi
fi

if [ -f /home/DOCKERUSER/init-firewall.sh ]; then
    /home/DOCKERUSER/init-firewall.sh || true
fi
if [ "$ENABLE_SUDO" = "true" ]; then
    echo "DOCKERUSER ALL=(ALL) NOPASSWD:ALL" > /etc/sudoers.d/DOCKERUSER
    chmod 0440 /etc/sudoers.d/DOCKERUSER
fi

if [ -n "$CLAUDEBOX_PROJECT_NAME" ]; then
    PROFILE_FILE="/home/DOCKERUSER/.claudebox/profiles/${CLAUDEBOX_PROJECT_NAME}.ini"

    if command -v uv >/dev/null 2>&1 && [ -f "$PROFILE_FILE" ] && grep -qE 'python|ml|datascience' "$PROFILE_FILE"; then
        if [ ! -d /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv ]; then
            su - DOCKERUSER -c "uv venv /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv"
            if [ -f /workspace/pyproject.toml ]; then
                su - DOCKERUSER -c "cd /workspace && uv sync"
            else
                su - DOCKERUSER -c "uv pip install --python /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/python ipython black pylint mypy flake8 pytest ruff"
            fi
        fi

        for shell_rc in /home/DOCKERUSER/.zshrc /home/DOCKERUSER/.bashrc; do
            if ! grep -q "source /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/activate" "$shell_rc"; then
                echo 'if [ -f /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/activate ]; then source /home/DOCKERUSER/.claudebox/$CLAUDEBOX_PROJECT_NAME/.venv/bin/activate; fi' >> "$shell_rc"
            fi
        done
    fi
fi

cd /home/DOCKERUSER
# Check if we're in shell mode
if [[ "${1:-}" == "--shell-mode" ]]; then
    shift  # Remove --shell-mode flag
    exec su DOCKERUSER -c "source /home/DOCKERUSER/.nvm/nvm.sh && cd /workspace && exec /bin/zsh"
else
    # Build command with properly quoted arguments
    cmd="cd /workspace && /home/DOCKERUSER/claude-wrapper"
    for arg in "$@"; do
        # Escape single quotes in the argument
        escaped_arg=$(echo "$arg" | sed "s/'/'\\\\''/g")
        cmd="$cmd '$escaped_arg'"
    done
    exec su DOCKERUSER -c "$cmd"
fi
EOF
}

run_docker_build() {
    info "Running docker build..."
    # Force BuildKit for better performance and features
    DOCKER_BUILDKIT=1 docker build \
        --build-arg USER_ID="$USER_ID" \
        --build-arg GROUP_ID="$GROUP_ID" \
        --build-arg USERNAME="$DOCKER_USER" \
        --build-arg NODE_VERSION="$NODE_VERSION" \
        -f "$1" -t "$IMAGE_NAME" "$2"
}

# Main execution
main() {
    update_symlink
    local project_folder_name
    project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
    IMAGE_NAME="claudebox-${project_folder_name}"
    # Check Docker
    local docker_status
    docker_status=$(check_docker; echo $?)
    case $docker_status in
        1) install_docker ;;
        2)
            warn "Docker is installed but not running."
            warn "Starting Docker requires sudo privileges..."
            sudo systemctl start docker
            docker info &>/dev/null || error "Failed to start Docker"
            docker ps &>/dev/null || configure_docker_nonroot
            ;;
        3)
            warn "Docker requires sudo. Setting up non-root access..."
            configure_docker_nonroot
            ;;
    esac

    # Check for rebuild, help, and verbose flags anywhere in arguments
    local args=("$@")
    local new_args=()
    local found_rebuild=false
    local found_help=false
    local VERBOSE=false

    for arg in "${args[@]}"; do
        if [[ "$arg" == "rebuild" ]]; then
            found_rebuild=true
        elif [[ "$arg" == "--verbose" ]]; then
            VERBOSE=true
            # strip it out so it doesn't become $1 later
        elif [[ "$arg" == "-h" || "$arg" == "--help" || "$arg" == "help" ]]; then
            # only global-help if it's literally the first token
            if [[ "${args[0]}" == "$arg" ]]; then
                found_help=true
            fi
            new_args+=("$arg")
        elif [[ "$arg" == "--enable-sudo" || "$arg" == "--disable-firewall" ]]; then
            # handled below
            continue
        else
            new_args+=("$arg")
        fi
    done

    if [[ "$found_rebuild" == "true" ]]; then
        # Compute IMAGE_NAME for rebuild
        local project_folder_name
        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
        IMAGE_NAME="claudebox-${project_folder_name}"
        warn "Rebuilding ClaudeBox Docker image..."
        if docker image inspect "$IMAGE_NAME" &>/dev/null; then
            docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
            docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
        fi
        set -- "${new_args[@]}"
    fi

    # Compute project folder name early
    local project_folder_name
        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
        IMAGE_NAME="claudebox-${project_folder_name}"
    project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
    IMAGE_NAME="claudebox-${project_folder_name}"
    PROJECT_CLAUDEBOX_DIR="$HOME/.claudebox/$project_folder_name"

    # Handle help immediately
    if [[ "$found_help" == "true" ]]; then
        if docker image inspect "$IMAGE_NAME" &>/dev/null; then
            docker run --rm \
                -u "$DOCKER_USER" \
                --entrypoint /home/$DOCKER_USER/claude-wrapper \
                "$IMAGE_NAME" --help | sed '1s/claude/claudebox/g'
            echo
            cecho "Added Options:" "$WHITE"
            echo -e "${CYAN}  --verbose                       ${WHITE}Show detailed output"
            echo -e "${CYAN}  --enable-sudo                   ${WHITE}Enable sudo without password"
            echo -e "${CYAN}  --disable-firewall              ${WHITE}Disable network restrictions"
            echo
            cecho "Added Commands:" "$WHITE"
            echo -e "  profile [names...]              Install language profiles"
            echo -e "  install <packages>              Install apt packages"
            echo -e "  save [flags...]                 Save default flags (no args = clear saved flags)"
            echo -e "  shell                           Open bash shell in container"
            echo -e "  info                            Show ClaudeBox container status"
            echo -e "  clean                           Clean up ClaudeBox resources (use 'clean --help' for options)"
            echo -e "  rebuild                         Rebuild the Docker image from scratch${NC}"
        else
            cecho "ClaudeBox - Claude Code Docker Environment" "$CYAN"
            echo
            warn "First run setup required!"
            echo "Run script without arguments first to build the Docker image."
        fi
        exit 0
    fi

    # Handle commands
    [[ "$VERBOSE" == "true" ]] && echo "Command: ${1:-none}" >&2
    case "${1:-}" in
        profile)
            shift
            if [[ $# -eq 0 ]]; then
                cecho "Available Profiles:" "$CYAN"
                echo
                for profile in $(printf '%s\n' "${!PROFILE_DESCRIPTIONS[@]}" | sort); do
                    echo -e "  ${GREEN}$profile${NC} - ${PROFILE_DESCRIPTIONS[$profile]}"
                done
                echo
                warn "Usage: claudebox profile <name> [<name2> ...]"
                warn "Example: claudebox profile c python web"
                exit 0
            fi

            local selected=() remaining=()
            while [[ $# -gt 0 ]]; do
                if [[ -n "${PROFILES[$1]:-}" ]]; then
                    selected+=("$1")
                    shift
                else
                    remaining=("$@")
                    break
                fi
            done

            [[ ${#selected[@]} -eq 0 ]] && error "No valid profiles specified\nRun 'claudebox profile' to see available profiles"

            local profile_file
            profile_file=$(get_profile_file_path)

            # Update profiles section
            update_profile_section "$profile_file" "profiles" "${selected[@]}"

            # Read all current profiles for display
            local all_profiles=()
            readarray -t all_profiles < <(read_profile_section "$profile_file" "profiles")

            cecho "Profile: $PROJECT_DIR" "$CYAN"
            cecho "Installing profiles: ${selected[*]}" "$PURPLE"
            if [[ ${#all_profiles[@]} -gt 0 ]]; then
                cecho "All active profiles: ${all_profiles[*]}" "$GREEN"
            fi
            echo

            # Continue to main execution to create container with profiles
            if [[ ${#remaining[@]} -gt 0 ]]; then
                set -- "${remaining[@]}"
            fi
            ;;
        save)
            shift
            defaults_file="$HOME/.claudebox/default-flags"

            if [[ $# -eq 0 ]]; then
                if [[ -f "$defaults_file" ]]; then
                    rm -f "$defaults_file"
                    success "Cleared saved default flags"
                else
                    info "No saved default flags to clear"
                fi
            else
                mkdir -p "$HOME/.claudebox"
                printf '%s\n' "$@" > "$defaults_file"
                success "Saved default flags: $*"
            fi
            exit 0
                        ;;
        install)
            shift
            [[ $# -eq 0 ]] && error "No packages specified. Usage: claudebox install <package1> <package2> ..."

            local profile_file
            profile_file=$(get_profile_file_path)

            # Update packages section
            update_profile_section "$profile_file" "packages" "$@"

            # Read all current packages for display
            local all_packages=()
            readarray -t all_packages < <(read_profile_section "$profile_file" "packages")

            cecho "Profile: $PROJECT_DIR" "$CYAN"
            cecho "Installing packages: $*" "$PURPLE"
            if [[ ${#all_packages[@]} -gt 0 ]]; then
                cecho "All packages: ${all_packages[*]}" "$GREEN"
            fi
            echo
            ;;


        update|config|mcp|migrate-installer)
            [[ ! -f /.dockerenv ]] && docker image inspect "$IMAGE_NAME" &>/dev/null || \
                error "ClaudeBox image not found.\nRun ${GREEN}claudebox${NC} first to build the image."
                        local project_folder_name
                        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
                        IMAGE_NAME="claudebox-${project_folder_name}"
            local cmd=$1
            shift

            info "Running $cmd command..."

            # Create temporary container
            local temp_container="claudebox-temp-${project_folder_name}-$$"
            docker run -d --name "$temp_container" \
                -v "$PROJECT_DIR":/workspace \
                -v "$CLAUDE_DATA_DIR":/home/$DOCKER_USER/.claude \
                -v "$HOME/.claudebox":/home/$DOCKER_USER/.claudebox \
                -v "$HOME/.config/claude":/home/$DOCKER_USER/.config/claude \
                -v "$HOME/.claude.json":/home/$DOCKER_USER/.claude.json.host:ro \
                -e "CLAUDEBOX_PROJECT_NAME=$project_folder_name" \
                "$IMAGE_NAME" --shell-mode >/dev/null

            if [[ "$cmd" == "update" ]]; then
                info "Updating Claude code..."
                docker exec -u "$DOCKER_USER" "$temp_container" bash -c "
                    source \$HOME/.nvm/nvm.sh
                    nvm use default
                    claude update
                    claude --version
                "
            else
                docker exec -it -u "$DOCKER_USER" "$temp_container" \
                    /home/$DOCKER_USER/claude-wrapper "${DEFAULT_FLAGS[@]}" "$cmd" "$@"
            fi

            # Commit changes back to image
            docker commit "$temp_container" "$IMAGE_NAME" >/dev/null
            docker stop "$temp_container" 2>/dev/null || true >/dev/null
            docker rm "$temp_container" 2>/dev/null || true

            success "$cmd completed and saved to image!"
            exit 0
            ;;

        shell)
            shift
            # Just add --shell-mode to the arguments and continue
            set -- "--shell-mode" "$@"
            ;;

        clean)
            shift
            case "${1:-}" in
                --help|-h)
                    cecho "ClaudeBox Clean Options:" "$CYAN"
                    echo
                    echo -e "  ${GREEN}clean${NC}                    Remove all containers (preserves image)"
                    echo -e "  ${GREEN}clean --project${NC}          Remove current project's data and profile"
                    echo -e "  ${GREEN}clean --all${NC}              Remove everything: containers, image, cache, symlink"
                    echo -e "  ${GREEN}clean --image${NC}            Remove containers and image (preserves build cache)"
                    echo -e "  ${GREEN}clean --cache${NC}            Remove Docker build cache only"
                    echo -e "  ${GREEN}clean --volumes${NC}          Remove associated Docker volumes"
                    echo -e "  ${GREEN}clean --symlink${NC}          Remove claudebox symlink only"
                    echo -e "  ${GREEN}clean --dangling${NC}         Remove dangling images and unused containers"
                    echo -e "  ${GREEN}clean --logs${NC}             Clear Docker container logs"
                    echo -e "  ${GREEN}clean --help${NC}             Show this help message"
                    echo
                    cecho "Examples:" "$YELLOW"
                    echo "  claudebox clean              # Remove all containers"
                    echo "  claudebox clean --project    # Remove only this project's container"
                    echo "  claudebox clean --image      # Remove containers and image"
                    echo "  claudebox clean --all        # Complete cleanup and reset"
                    exit 0
                    ;;
                --all|-a)
                    warn "Complete ClaudeBox cleanup: removing containers, image, cache, and symlink..."
                    # Remove all profile files
                    rm -rf "$HOME/.claudebox/profiles"
                    # Remove any containers from this image
                    docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
                    # Remove orphaned containers from images that no longer exist
                    # This is safer as it only removes containers whose images are gone
                    docker ps -a --filter "status=exited" --format "{{.ID}} {{.Image}}" | while read id image; do
                        if ! docker image inspect "$image" >/dev/null 2>&1; then
                            docker rm -f "$id" 2>/dev/null || true
                        fi
                    done
                   # Remove all claudebox project images
                   docker images --filter "reference=claudebox-*" -q | xargs -r docker rmi -f 2>/dev/null || true
                    # Remove image
                    docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
                    # Prune build cache
                    docker builder prune -af 2>/dev/null || true
                    # Remove volumes
                    docker volume ls -q --filter "name=claudebox" | xargs -r docker volume rm 2>/dev/null || true
                    # Remove symlink
                    [[ -L "$LINK_TARGET" ]] && rm -f "$LINK_TARGET" && info "Removed claudebox symlink"
                    success "Complete cleanup finished!"
                    ;;
                --image|-i)
                    warn "Removing ClaudeBox containers and image..."
                    # Remove all profile files
                    rm -rf "$HOME/.claudebox/profiles"
                    # Remove any containers from this image
                    docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
                    # Remove orphaned containers from images that no longer exist
                    # This is safer as it only removes containers whose images are gone
                    docker ps -a --filter "status=exited" --format "{{.ID}} {{.Image}}" | while read id image; do
                        if ! docker image inspect "$image" >/dev/null 2>&1; then
                            docker rm -f "$id" 2>/dev/null || true
                        fi
                    done
                   # Remove all claudebox project images
                   docker images --filter "reference=claudebox-*" -q | xargs -r docker rmi -f 2>/dev/null || true
                    docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
                    success "Containers and image removed! Build cache preserved."
                    ;;
                --cache|-c)
                    warn "Cleaning Docker build cache..."
                    docker builder prune -af
                    success "Build cache cleaned!"
                    ;;
                --volumes|-v)
                    warn "Removing ClaudeBox-related volumes..."
                    docker volume ls -q --filter "name=claudebox" | xargs -r docker volume rm 2>/dev/null || true
                    docker volume prune -f 2>/dev/null || true
                    success "Volumes cleaned!"
                    ;;
                --symlink|-s)
                    if [[ -L "$LINK_TARGET" ]]; then
                        rm -f "$LINK_TARGET"
                        success "Removed claudebox symlink from $(dirname "$LINK_TARGET")"
                    else
                        info "No claudebox symlink found at $LINK_TARGET"
                    fi
                    exit 0
                    ;;
                --dangling|-d)
                    warn "Removing dangling images and unused containers..."
                    docker image prune -f
                    docker container prune -f
                    success "Dangling resources cleaned!"
                    ;;
                --logs|-l)
                    warn "Clearing Docker container logs..."
                    docker ps -a --filter "label=claudebox.project" -q | while read -r container; do
                        docker logs "$container" >/dev/null 2>&1 && echo -n | docker logs "$container" 2>/dev/null || true
                    done
                    success "Container logs cleared!"
                    ;;
                --project|-p)
                    warn "Removing data for current project: $PROJECT_DIR"
                    local profile_file
                    profile_file=$(get_profile_file_path)

                    # Remove profile
                    if [[ -f "$profile_file" ]]; then
                        rm -f "$profile_file"
                        success "Removed profile for $PROJECT_DIR"
                    fi

                    # Remove project-specific folder
                    local project_folder_name
        project_folder_name=$(get_project_folder_name "$PROJECT_DIR")
        IMAGE_NAME="claudebox-${project_folder_name}"
                    local project_claudebox_dir="$HOME/.claudebox/$project_folder_name"
    local image_name="claudebox-${project_folder_name}"

                    if [[ -d "$project_claudebox_dir" ]]; then
                        rm -rf "$project_claudebox_dir"
                        success "Removed project data folder: $project_claudebox_dir"

    # Remove project Docker image
    docker rmi -f "$image_name" 2>/dev/null || true
    success "Removed project Docker image: $image_name"
                    else
                        info "No project data folder found"
                    fi
                    exit 0
                    ;;
                *)
                    warn "Cleaning ClaudeBox containers..."
                    # Remove all profile files
                    rm -rf "$HOME/.claudebox/profiles"
                    # Remove any containers from this image
                    docker ps -a --filter "label=claudebox.project" -q | xargs -r docker rm -f 2>/dev/null || true
                    # Remove orphaned containers from images that no longer exist
                    # This is safer as it only removes containers whose images are gone
                    docker ps -a --filter "status=exited" --format "{{.ID}} {{.Image}}" | while read id image; do
                        if ! docker image inspect "$image" >/dev/null 2>&1; then
                            docker rm -f "$id" 2>/dev/null || true
                        fi
                    done
                   # Remove all claudebox project images
                   docker images --filter "reference=claudebox-*" -q | xargs -r docker rmi -f 2>/dev/null || true
                    success "Containers removed! Image preserved for quick recreation."
                    ;;
            esac
            echo
            docker system df
            exit 0
            ;;

        help|--help|-h)
            if docker image inspect "$IMAGE_NAME" &>/dev/null; then
                docker run --rm \
                    -u "$DOCKER_USER" \
                    --entrypoint /home/$DOCKER_USER/claude-wrapper \
                    "$IMAGE_NAME" --help | sed '1s/claude/claudebox/g'
                echo
                cecho "Added Options:" "$WHITE"
                echo -e "${CYAN}  --verbose                       ${WHITE}Show detailed output"
                echo -e "${CYAN}  --enable-sudo                   ${WHITE}Enable sudo without password"
                echo -e "${CYAN}  --disable-firewall              ${WHITE}Disable network restrictions"
                echo
                cecho "Added Commands:" "$WHITE"
                echo -e "  profile [names...]              Install language profiles"
                echo -e "  install <packages>              Install apt packages"
                echo -e "  save [flags...]                 Save default flags (no args = clear saved flags)"
                echo -e "  shell                           Open bash shell in container"
                echo -e "  info                            Show ClaudeBox container status"
                echo -e "  clean                           Clean up ClaudeBox resources (use 'clean --help' for options)"
                echo -e "  rebuild                         Rebuild the Docker image from scratch${NC}"
            else
                cecho "ClaudeBox - Claude Code Docker Environment" "$CYAN"
                echo
                warn "First run setup required!"
                echo "Run script without arguments first to build the Docker image."
            fi
            exit 0
            ;;

        info)
            shift
            cecho "ClaudeBox Profile Status" "$CYAN"
            echo

            local profile_dir="$HOME/.claudebox/profiles"
            if [[ ! -d "$profile_dir" ]] || [[ -z "$(ls -A "$profile_dir" 2>/dev/null)" ]]; then
                warn "No profiles configured yet."
                exit 0
            fi

            # Show all profiles
            local count
            count=$(ls -1 "$profile_dir"/*.ini 2>/dev/null | wc -l)
            info "Tracking $count project profile(s)"
            echo

            # Show each project's profiles
            for pfile in "$profile_dir"/*.ini; do
                [[ -f "$pfile" ]] || continue
                local proj_path
                proj_path=$(basename "$pfile" .ini | sed 's|-|/|g')
                cecho "/$proj_path:" "$YELLOW"

                # Show profiles
                local profiles=()
                readarray -t profiles < <(read_profile_section "$pfile" "profiles")
                if [[ ${#profiles[@]} -gt 0 ]]; then
                    echo "  Profiles: ${profiles[*]}"
                fi

                # Show packages
                local packages=()
                readarray -t packages < <(read_profile_section "$pfile" "packages")
                if [[ ${#packages[@]} -gt 0 ]]; then
                    echo "  Packages: ${packages[*]}"
                fi
                echo
            done

            # Show current project's profiles
            local current_profile_file
            current_profile_file=$(get_profile_file_path)
            if [[ -f "$current_profile_file" ]]; then
                cecho "Current project ($PROJECT_DIR):" "$GREEN"
                local current_profiles=()
                readarray -t current_profiles < <(read_profile_section "$current_profile_file" "profiles")
                if [[ ${#current_profiles[@]} -gt 0 ]]; then
                    echo "  Profiles: ${current_profiles[*]}"
                fi

                local current_packages=()
                readarray -t current_packages < <(read_profile_section "$current_profile_file" "packages")
                if [[ ${#current_packages[@]} -gt 0 ]]; then
                    echo "  Packages: ${current_packages[*]}"
                fi
            else
                info "Current project has no profiles configured."
            fi

            # Show running containers
            echo
            local running_containers
            running_containers=$(docker ps --filter "ancestor=$IMAGE_NAME" --format "table {{.ID}}\t{{.Status}}\t{{.Command}}" | tail -n +2)
            if [[ -n "$running_containers" ]]; then
                cecho "Running ClaudeBox containers:" "$YELLOW"
                echo "$running_containers"
            else
                info "No ClaudeBox containers currently running."
            fi

            # Show all ClaudeBox images
            echo
            local claudebox_images
            claudebox_images=$(docker images --filter "reference=claudebox-*" --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | tail -n +1)
            if [[ -n "$claudebox_images" ]]; then
                cecho "ClaudeBox Docker Images:" "$YELLOW"
                echo "$claudebox_images"
            fi


            exit 0
            ;;

    esac

    # Setup workspace and global config
    setup_project_folder
    setup_claude_agent_command

    # Profile tracking
    mkdir -p "$HOME/.claudebox/profiles"

    # Check if we need to rebuild based on profiles
    local need_rebuild=false
    local current_profiles=()
    local profile_hash=""

    # Read profiles for current project only
    if [[ -d "$HOME/.claudebox/profiles" ]]; then
        for profile_file in "$HOME/.claudebox/profiles"/*.ini; do
            [[ -f "$profile_file" ]] || continue
            local profiles_from_file=()
            readarray -t profiles_from_file < <(read_profile_section "$profile_file" "profiles")
            for profile in "${profiles_from_file[@]}"; do
                profile=$(echo "$profile" | tr -d '[:space:]')
                [[ -z "$profile" ]] && continue
                # Add to array if not already present
                local found=false
                for p in "${current_profiles[@]}"; do
                    [[ "$p" == "$profile" ]] && found=true && break
                                done
                [[ "$found" == "false" ]] && current_profiles+=("$profile")
            done
        done

        if [[ ${#current_profiles[@]} -gt 0 ]]; then
            profile_hash=$(printf '%s\n' "${current_profiles[@]}" | sort | sha256sum | cut -d' ' -f1)
        fi
    fi

    # Check if image exists and if profiles match
    if docker image inspect "$IMAGE_NAME" >/dev/null 2>&1; then
        # Get the profile hash from the image labels
        local image_profile_hash
        image_profile_hash=$(docker inspect "$IMAGE_NAME" --format '{{index .Config.Labels "claudebox.profiles"}}' 2>/dev/null || echo "")

        if [[ "$profile_hash" != "$image_profile_hash" ]]; then
            warn "Profiles have changed. Rebuilding image..."
            warn "Current profiles: ${current_profiles[*]}"
            docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
            need_rebuild=true
        fi
    else
        need_rebuild=true
    fi

        # Build image if needed
        if [[ "$need_rebuild" == "true" ]] || ! docker image inspect "$IMAGE_NAME" >/dev/null 2>&1; then
                logo
                local build_context="$HOME/.claudebox/build"
                mkdir -p "$build_context"
                local dockerfile="$build_context/Dockerfile"

        create_build_files "$build_context"

    # Get the latest delta version at build time
    info "Fetching latest git-delta version..."
    LATEST_DELTA_VERSION=$(curl -s https://api.github.com/repos/dandavison/delta/releases/latest | grep -Po '"tag_name": "\K[^"]*')
    info "Using git-delta version: $LATEST_DELTA_VERSION"

        cat > "$dockerfile" <<'DOCKERFILE'
FROM debian:bookworm
ARG USER_ID GROUP_ID USERNAME NODE_VERSION

RUN echo '#!/bin/sh\nexit 101' > /usr/sbin/policy-rc.d && chmod +x /usr/sbin/policy-rc.d

# Install locales first to fix locale warnings
RUN export DEBIAN_FRONTEND=noninteractive && \
    apt-get update -qq && \
        apt-get install -y --no-autoremove --no-install-recommends nala curl locales && apt-get clean && \
    echo "en_US.UTF-8 UTF-8" > /etc/locale.gen && locale-gen en_US.UTF-8 &&\
        curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg && \
    chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg && \
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg]" \
    "https://cli.github.com/packages stable main" | tee /etc/apt/sources.list.d/github-cli.list > /dev/null && nala update && \
        nala install -y --no-autoremove --no-install-recommends apt-utils wget zsh fzf gnupg ca-certificates sudo git iptables ipset gh unzip jq \
        sudo procps vim nano less ca-certificates && \
        rm -rf /var/lib/apt/lists/*

# Set locale environment variables
ENV LANG=en_US.UTF-8 \
    LANGUAGE=en_US:en \
    LC_ALL=en_US.UTF-8

RUN groupadd -g $GROUP_ID $USERNAME || true && \
    useradd -m -u $USER_ID -g $GROUP_ID -s /bin/bash $USERNAME

RUN DELTA_VERSION=$(curl -s https://api.github.com/repos/dandavison/delta/releases/latest | grep -Po '"tag_name": "\K[^"]*') && \
    ARCH=$(dpkg --print-architecture) && \
    wget -q https://github.com/dandavison/delta/releases/download/${DELTA_VERSION}/git-delta_${DELTA_VERSION}_${ARCH}.deb && \
    dpkg -i git-delta_${DELTA_VERSION}_${ARCH}.deb && \
    rm git-delta_${DELTA_VERSION}_${ARCH}.deb

USER $USERNAME
WORKDIR /home/$USERNAME

RUN sh -c "$(wget -O- https://github.com/deluan/zsh-in-docker/releases/download/v1.2.0/zsh-in-docker.sh)" -- \
    -p git \
    -p fzf \
    -a "source /usr/share/doc/fzf/examples/key-bindings.zsh" \
    -a "source /usr/share/doc/fzf/examples/completion.zsh" \
    -a 'export HISTFILE="/home/$USERNAME/.claudebox/.zsh_history"' \
    -a 'export HISTSIZE=10000' \
    -a 'export SAVEHIST=10000' \
    -a 'setopt HIST_IGNORE_DUPS' \
    -a 'setopt SHARE_HISTORY' \
    -a 'export NVM_DIR="$HOME/.nvm"' \
    -a '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' \
    -a '[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"' \
    -x

RUN curl -LsSf https://astral.sh/uv/install.sh | sh

RUN echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc && \
    echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.zshrc

RUN git config --global core.pager delta && \
    git config --global interactive.diffFilter "delta --color-only" && \
    git config --global delta.navigate true && \
    git config --global delta.light false && \
    git config --global delta.side-by-side true

# Set DEVCONTAINER environment variable to help with orientation
ENV DEVCONTAINER=true

# Set the default shell to zsh rather than sh
ENV SHELL=/bin/zsh

ENV NVM_DIR="/home/$USERNAME/.nvm"
RUN curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash

RUN bash -c "source $NVM_DIR/nvm.sh && \
    if [[ \"$NODE_VERSION\" == '--lts' ]]; then \
        nvm install --lts && \
        nvm alias default 'lts/*'; \
    else \
        nvm install $NODE_VERSION && \
        nvm alias default $NODE_VERSION; \
    fi && \
    nvm use default"

RUN echo 'export NVM_DIR="$HOME/.nvm"' >> ~/.bashrc && \
    echo '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' >> ~/.bashrc && \
    echo '[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"' >> ~/.bashrc

RUN bash -c "source $NVM_DIR/nvm.sh && \
    nvm use default && \
    npm install -g @anthropic-ai/claude-code"


# Install profile packages as separate layers for better caching
USER root
DOCKERFILE
        if [[ ${#current_profiles[@]} -gt 0 ]]; then
                info "Building with profiles: ${current_profiles[*]}"

                # Resolve and deduplicate all dependency layers
                resolved_profiles=()
                for profile in "${current_profiles[@]}"; do
                        resolved_profiles+=($(expand_profile "$profile"))
                done

                unique_profiles=($(awk -v RS=' ' '!seen[$1]++' <<< "${resolved_profiles[*]}"))

                # APT install layers (1 per profile)
                for profile in "${unique_profiles[@]}"; do
                        pkg_list=(${PROFILES[$profile]:-})
                        [[ ${#pkg_list[@]} -eq 0 ]] && continue

        cat >> "$dockerfile" <<DOCKERFILE
# ${PROFILE_DESCRIPTIONS[$profile]}
RUN export DEBIAN_FRONTEND=noninteractive && \\
        apt-get update -qq && \\
        nala install -y --no-autoremove ${pkg_list[*]} && \\
        nala clean && rm -rf /var/lib/apt/lists/*
DOCKERFILE
                                case "$profile" in
                                        rust)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y && \
        echo 'source $HOME/.cargo/env' >> ~/.bashrc && \
        echo 'source $HOME/.cargo/env' >> ~/.zshrc
USER root
DOCKERFILE
                                                ;;
                                        go)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
RUN GO_VERSION="1.21.5" && \
        wget -q "https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz" && \
        tar -C /usr/local -xzf "go${GO_VERSION}.linux-amd64.tar.gz" && \
        rm "go${GO_VERSION}.linux-amd64.tar.gz" && \
        echo 'export PATH=$PATH:/usr/local/go/bin' >> /etc/profile.d/go.sh
DOCKERFILE
                                                ;;
                                        python)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN ~/.local/bin/uv pip install ipython black mypy pylint pytest ruff poetry pipenv
USER root
DOCKERFILE
                                                ;;
                                        ml)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN ~/.local/bin/uv pip install torch transformers scikit-learn numpy pandas matplotlib
USER root
DOCKERFILE
                                                ;;
                                        datascience)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN ~/.local/bin/uv pip install jupyter notebook jupyterlab numpy pandas scipy matplotlib seaborn scikit-learn statsmodels plotly
USER root
DOCKERFILE
                                                ;;
                                        javascript)
                                                cat >> "$dockerfile" <<'DOCKERFILE'
USER $USERNAME
RUN bash -c "source \$NVM_DIR/nvm.sh && npm install -g typescript eslint prettier yarn pnpm"
USER root
DOCKERFILE
                                                ;;
                                        *) : ;;
                                esac
                        done
                fi

        # Add label with profile hash
        echo "# Label the image with the profile hash for change detection" >> "$dockerfile"
        echo "LABEL claudebox.profiles=\"$profile_hash\"" >> "$dockerfile"
        echo "LABEL claudebox.project=\"$project_folder_name\"" >> "$dockerfile"
        echo "" >> "$dockerfile"
        cat >> "$dockerfile" <<'DOCKERFILE'

USER $USERNAME
RUN bash -c "source $NVM_DIR/nvm.sh && claude --version"

# Copy Claude wrapper script
COPY --chown=$USERNAME --chmod=755 claude-wrapper /home/$USERNAME/claude-wrapper

# Copy firewall script
COPY --chown=$USERNAME --chmod=755 init-firewall /home/$USERNAME/init-firewall

WORKDIR /workspace
USER root
COPY --chown=$USERNAME docker-entrypoint.sh /usr/local/bin/docker-entrypoint
RUN sed -i "s/DOCKERUSER/$USERNAME/g" /usr/local/bin/docker-entrypoint && \
    sed -i "s/DOCKERUSER/$USERNAME/g" /home/$USERNAME/init-firewall && \
    chmod +x /usr/local/bin/docker-entrypoint

ENTRYPOINT ["/usr/local/bin/docker-entrypoint"]
DOCKERFILE

        run_docker_build "$dockerfile" "$build_context"

        echo -e "\n${GREEN}Complete!${NC}\n"
        success "Docker image '$IMAGE_NAME' built!"

        echo
        cecho "ClaudeBox Setup Complete!" "$CYAN"
        echo
        cecho "Quick Start:" "$GREEN"
        echo -e "  ${YELLOW}claudebox [options]${NC}        # Launch Claude CLI"
        echo
        cecho "Power Features:" "$GREEN"
        echo -e "  ${YELLOW}claudebox profile${NC}                # See all language profiles"
        echo -e "  ${YELLOW}claudebox profile c openwrt${NC}      # Install C + OpenWRT tools"
        echo -e "  ${YELLOW}claudebox profile python ml${NC}      # Install Python + ML stack"
        echo -e "  ${YELLOW}claudebox install <packages>${NC}     # Install additional apt packages"
        echo -e "  ${YELLOW}claudebox shell${NC}                  # Open bash shell in container"
        echo
        cecho "Security:" "$GREEN"
        echo -e "  Network firewall: ON by default (Anthropic recommended)"
        echo -e "  Sudo access: OFF by default"
        echo
        cecho "Maintenance:" "$GREEN"
        echo -e "  ${YELLOW}claudebox clean --help${NC}            # See all cleanup options"
        echo
        cecho "Just install the profile you need and start coding!" "$PURPLE"
       exit 0
   fi

   # Run container
   local extra_mounts=()

   # Ensure .claudebox exists with proper permissions
   if [[ ! -d "$HOME/.claudebox" ]]; then
       mkdir -p "$HOME/.claudebox"
   fi

   # Fix permissions if needed
   if [[ ! -w "$HOME/.claudebox" ]]; then
       warn "Fixing .claudebox permissions..."
       sudo chown -R "$USER:$USER" "$HOME/.claudebox" || true
   fi

   # Create project-specific allowlist if it doesn't exist
   local allowlist_file="$PROJECT_CLAUDEBOX_DIR/firewall/allowlist"

   if [[ ! -f "$allowlist_file" ]]; then
       mkdir -p "$(dirname "$allowlist_file")"
       info "Creating default firewall allowlist for project..."
       cat > "$allowlist_file" <<'EOF'
# ClaudeBox Firewall Allowlist
# Lines starting with # are comments
# Add one domain or IP range per line
#
# Default domains (always allowed):
# - api.anthropic.com
# - console.anthropic.com
# - statsig.anthropic.com
# - sentry.io

# ====================
# GitHub.com
# ====================
github.com
api.github.com
raw.githubusercontent.com
ssh.github.com
avatars.githubusercontent.com
codeload.github.com
objects.githubusercontent.com
pipelines.actions.githubusercontent.com
ghcr.io
pkg-containers.githubusercontent.com

# ====================
# GitLab.com
# ====================
gitlab.com
api.gitlab.com
registry.gitlab.com
uploads.gitlab.com
gitlab.io
*.gitlab.io
*.s3.amazonaws.com
*.amazonaws.com

# ====================
# Bitbucket.org
# ====================
bitbucket.org
api.bitbucket.org
altssh.bitbucket.org
bbuseruploads.s3.amazonaws.com
bitbucket-pipelines-prod-us-west-2.s3.amazonaws.com
bitbucket-pipelines-prod-us-east-1.s3.amazonaws.com
bitbucket-pipelines-prod-eu-west-1.s3.amazonaws.com

# ====================
# Atlassian IP Ranges (Bitbucket Cloud)
# ====================
104.192.136.0/21
185.166.140.0/22
13.200.41.128/25
18.246.31.128/25

# ====================
# Optional (Git LFS, Assets)
# ====================
github-cloud.s3.amazonaws.com
github-releases.githubusercontent.com
github-production-release-asset-2e65be.s3.amazonaws.com
EOF
       success "Created default allowlist"
   fi

   set -- "${DEFAULT_FLAGS[@]}" "$@"

   # Build Docker arguments
   local docker_args=()
   [[ "$ENABLE_SUDO" == "true" ]] && docker_args+=("--enable-sudo")
   [[ "$DISABLE_FIREWALL" == "true" ]] && docker_args+=("--disable-firewall")

   docker run -it --rm --init \
       -w /workspace \
       -v "$PROJECT_DIR":/workspace \
       -v "$CLAUDE_DATA_DIR":/home/$DOCKER_USER/.claude \
       -v "$HOME/.claudebox":/home/$DOCKER_USER/.claudebox \
       -v "$HOME/.config/claude":/home/$DOCKER_USER/.config/claude \
       -v "$HOME/.claude.json":/home/$DOCKER_USER/.claude.json.host:ro \
       -v "$HOME/.npmrc":/home/$DOCKER_USER/.npmrc:ro \
       -v "$HOME/.ssh":/home/$DOCKER_USER/.ssh:ro \
       -e "NODE_ENV=${NODE_ENV:-production}" \
       -e "ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}" \
       -e "CLAUDEBOX_PROJECT_NAME=$project_folder_name" \
       --cap-add NET_ADMIN \
       --cap-add NET_RAW \
       "$IMAGE_NAME" "${docker_args[@]}" "$@"
}

main "$@"
