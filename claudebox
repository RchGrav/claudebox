#!/usr/bin/env bash
set -euo pipefail
cb='
 ██████╗██╗      █████╗ ██╗   ██╗██████╗ ███████╗
██╔════╝██║     ██╔══██╗██║   ██║██╔══██╗██╔════╝
██║     ██║     ███████║██║   ██║██║  ██║█████╗
██║     ██║     ██╔══██║██║   ██║██║  ██║██╔══╝
╚██████╗███████╗██║  ██║╚██████╔╝██████╔╝███████╗
 ╚═════╝╚══════╝╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝

██████╗  ██████╗ ██╗  ██╗ ------ ┌──────────────┐
██╔══██╗██╔═══██╗╚██╗██╔╝ ------ │ The Ultimate │
██████╔╝██║   ██║ ╚███╔╝  ------ │ Claude Code  │
██╔══██╗██║   ██║ ██╔██╗  ------ │  Docker Dev  │
██████╔╝╚██████╔╝██╔╝ ██╗ ------ │ Environment  │
╚═════╝  ╚═════╝ ╚═╝  ╚═╝ ------ └──────────────┘
'
# Configuration
IMAGE_NAME="claudebox"
DOCKER_USER="claude"
USER_ID=$(id -u)
GROUP_ID=$(id -g)
PROJECT_DIR="$(pwd)"
SCRIPT_PATH="$(realpath "$0")"
CLAUDE_DATA_DIR="$HOME/.claude"
LINK_TARGET="/usr/local/bin/claudebox"
DOCKERFILE="$(mktemp /tmp/claudebox-dockerfile.XXXXXX)"
NODE_VERSION="--lts"
USER_ARGS=("$@")
# USER_ARGS+=("--dangerously-skip-permissions") # Removed hardcoded flag
#USER_ARGS+=("--dangerously-enable-sudo")
# USER_ARGS+=("--dangerously-disable-firewall") # Removed hardcoded flag

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

# Approval Mechanism
CLAUDEBOX_AUTO_APPROVE_TIER1="${CLAUDEBOX_AUTO_APPROVE_TIER1:-false}"
CLAUDEBOX_AUTO_APPROVE_TIER2_DANGEROUS="${CLAUDEBOX_AUTO_APPROVE_TIER2_DANGEROUS:-false}" # For truly headless/scripted use of dangerous ops

confirm_action() {
    local level="$1"
    local description="$2"
    local confirmation_keyword="${3:-}" # For Tier 2, this is mandatory
    local current_command_name="${USER_ARGS[0]:-}" # Get the command name like 'profile', 'clean', etc.

    # If no specific command (e.g. direct script execution for first time setup), use a generic name
    if [[ -z "$current_command_name" || "$current_command_name" == -* ]]; then # if it's an option, not a command
        current_command_name="initial_setup"
    fi

    local effective_keyword="${confirmation_keyword:-$current_command_name}"
    if [[ -z "$effective_keyword" ]]; then # Should not happen if keyword is mandatory for Tier 2
        effective_keyword="proceed"
    fi

    echo # Newline for readability
    echo -e "${YELLOW}Confirmation required for 'claudebox ${current_command_name}'${NC}"
    echo -e "${CYAN}Description: ${description}${NC}"

    local dangerous_flags_active=()
    for arg in "${USER_ARGS[@]}"; do
        if [[ "$arg" == "--dangerously-enable-sudo" || "$arg" == "--dangerously-disable-firewall" || "$arg" == "--dangerously-skip-permissions" ]]; then
            dangerous_flags_active+=("$arg")
        fi
    done

    if [[ ${#dangerous_flags_active[@]} -gt 0 ]]; then
        echo -e "${RED}🔥 NOTICE: The following 'dangerous' flag(s) are active and will be passed to Docker/Claude: ${dangerous_flags_active[*]}${NC}"
    fi

    if [[ "$level" -eq 1 ]]; then
        if [[ "$CLAUDEBOX_AUTO_APPROVE_TIER1" == "true" ]]; then
            echo -e "${GREEN}Tier 1 action automatically approved via CLAUDEBOX_AUTO_APPROVE_TIER1.${NC}"
            return 0
        fi
        read -r -p "Do you want to continue? (y/N): " response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            return 0
        else
            echo -e "${RED}Action cancelled by user.${NC}"
            exit 1 # Critical exit, this is a safety mechanism
        fi
    elif [[ "$level" -eq 2 ]]; then
        if [[ "$CLAUDEBOX_AUTO_APPROVE_TIER2_DANGEROUS" == "true" && -n "$confirmation_keyword" ]]; then
             echo -e "${RED}🔥 Tier 2 action automatically approved via CLAUDEBOX_AUTO_APPROVE_TIER2_DANGEROUS. This is risky. 🔥${NC}"
             return 0
        fi
        echo -e "${RED}⚠️ WARNING: This is a privileged or destructive operation.${NC}"
        read -r -p "To confirm this action, please type '${effective_keyword}': " response
        if [[ "$response" == "$effective_keyword" ]]; then
            return 0
        else
            echo -e "${RED}Confirmation failed. Action cancelled.${NC}"
            exit 1 # Critical exit
        fi
    else
        echo -e "${RED}Developer error: Invalid confirmation level '$level' passed to confirm_action.${NC}"
        exit 2 # Scripting error
    fi
}

# --- Utility Functions ---
sanitize_input_for_command() {
    local input="$1"
    # Allow alphanumeric, underscores, hyphens, periods (for versions like 1.2.3),
    # colons (for versions like 1:2.3-4), tildes (for versions like 1.2.3~beta)
    # plus signs (for versions like 1.2.3+build4 or g++-11).
    # Essentially, characters common in valid package names and versions.
    # Critical: Disallow spaces, semicolons, pipes, ampersands, backticks, command substitutions like $() etc.
    if [[ "$input" =~ ^[a-zA-Z0-9_.+:-]+$ ]]; then
        echo "$input"
    else
        # Return empty or some other indicator of invalid input
        # For now, returning empty and letting the caller handle it.
        echo ""
    fi
}
# --- End Utility Functions ---

check_docker() {
    if ! command -v docker &> /dev/null; then
        return 1  # Docker not installed
    fi

    # Check if docker daemon is running
    if ! docker info &> /dev/null; then
        return 2  # Docker installed but not running
    fi

    # Check if user can run docker without sudo
    if ! docker ps &> /dev/null; then
        return 3  # Docker requires sudo
    fi

    return 0  # Docker is working perfectly
}

# Function to install Docker
install_docker() {
    echo -e "${YELLOW}Docker is not installed.${NC}"
    # Tier 1 style confirmation for initial Docker install prompt, but it's a lead-in to Tier 2.
    # The main Tier 2 confirmation is below.
    if [[ "$CLAUDEBOX_AUTO_APPROVE_TIER1" != "true" ]]; then # Allow skipping this initial y/n if auto-approving Tier 1
        echo -e "${CYAN}Would you like to attempt Docker installation now? (y/n)${NC}"
        read -r response
        if [[ ! "$response" =~ ^[Yy]$ ]]; then
            echo -e "${RED}Docker is required for ClaudeBox. Please install Docker and try again.${NC}"
            echo -e "${YELLOW}Visit: https://docs.docker.com/engine/install/${NC}"
            exit 1
        fi
    fi

    confirm_action 2 "Install Docker on your system. This requires sudo privileges for package management and system changes." "install_docker"
    echo -e "${BLUE}Proceeding with Docker installation steps...${NC}"

    # Detect OS
    if [[ -f /etc/os-release ]]; then
        . /etc/os-release
        OS=$ID
    else
        echo -e "${RED}Cannot detect OS. Please install Docker manually.${NC}"
        exit 1
    fi

    case $OS in
        ubuntu|debian)
            echo -e "${YELLOW}Installing Docker (Debian/Ubuntu) - sudo privileges will be requested by commands below.${NC}"

            sudo apt-get update
            sudo apt-get install -y ca-certificates curl gnupg lsb-release
            sudo mkdir -p /etc/apt/keyrings
            # The curl to gpg and tee commands inherently use sudo if needed by user permissions on target files/dirs
            curl -fsSL https://download.docker.com/linux/$OS/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/$OS $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            sudo apt-get update
            sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            ;;

        fedora|rhel|centos)
            echo -e "${YELLOW}Installing Docker (Fedora) - sudo privileges will be requested by commands below.${NC}"

            sudo dnf -y install dnf-plugins-core
            sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo
            sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

            confirm_action 2 "Start and enable Docker service using systemctl. This requires sudo." "manage_docker_service"
            sudo systemctl start docker
            sudo systemctl enable docker
            ;;

        arch|manjaro)
            echo -e "${YELLOW}Installing Docker (Arch) - sudo privileges will be requested by commands below.${NC}"
            sudo pacman -S --noconfirm docker

            confirm_action 2 "Start and enable Docker service using systemctl. This requires sudo." "manage_docker_service"
            sudo systemctl start docker
            sudo systemctl enable docker
            ;;

        *)
            echo -e "${RED}Unsupported OS: $OS${NC}"
            echo -e "${YELLOW}Please install Docker manually and run this script again.${NC}"
            echo -e "${YELLOW}Visit: https://docs.docker.com/engine/install/${NC}"
            exit 1
            ;;
    esac

    echo -e "${GREEN}Docker installed successfully!${NC}"

    # Now configure for non-root usage
    configure_docker_nonroot
}

# Function to configure Docker for non-root usage
configure_docker_nonroot() {
    confirm_action 2 "Configure Docker for non-root usage by adding user '$USER' to the 'docker' group. This requires sudo for group management." "configure_docker_group"
    echo -e "${BLUE}Proceeding with Docker non-root configuration...${NC}"

    if ! getent group docker > /dev/null; then
        sudo groupadd docker
    fi
    sudo usermod -aG docker "$USER"
    echo -e "${GREEN}Docker non-root usage configured!${NC}"
    echo -e "${YELLOW}You need to log out and back in for group changes to take effect.${NC}"
    echo -e "${YELLOW}Or run: ${CYAN}newgrp docker${NC}"
    echo -e "${YELLOW}Then run 'claudebox' again.${NC}"

    # Try to activate the group in current shell
    echo -e "${BLUE}Trying to activate docker group in current shell...${NC}"
    exec newgrp docker
}

# Logo drawing function
logo() {
    while IFS= read -r l; do
        o="" c=""
        for ((i=0;i<${#l};i++)); do
            ch="${l:$i:1}"
            [[ "$ch" == " " ]] && { o+="$ch"; continue; }
            cc=$(printf '%d' "'$ch" 2>/dev/null||echo 0)
            if [[ $cc -ge 32 && $cc -le 126 ]]; then n='\033[33m'
            elif [[ $cc -ge 9552 && $cc -le 9580 ]]; then n='\033[34m'
            elif [[ $cc -eq 9608 ]]; then n='\033[31m'
            else n='\033[37m'; fi
            [[ "$n" != "$c" ]] && { o+="$n"; c="$n"; }
            o+="$ch"
        done
        echo -e "${o}\033[0m"
    done <<< "$cb"
}


# Check Docker installation and permissions
docker_status=$(check_docker; echo $?)

case $docker_status in
    1)
        # Docker not installed - need to install
        install_docker
        ;;
    2)
        # Docker installed but not running - need sudo to start it
        echo -e "${YELLOW}Docker is installed but not running.${NC}"
        confirm_action 2 "Start Docker service using systemctl. This requires sudo." "manage_docker_service"
        sudo systemctl start docker
        if ! docker info &> /dev/null; then
            echo -e "${RED}Failed to start Docker. Please check your Docker installation.${NC}"
            exit 1
        fi

        # Check if we need to configure non-root access
        if ! docker ps &> /dev/null; then
            configure_docker_nonroot
        fi
        ;;
    3)
        # Docker requires sudo - configure non-root access
        echo -e "${YELLOW}Docker requires sudo. Setting up non-root access...${NC}"
        configure_docker_nonroot
        ;;
esac

# Profile definitions - THE MEGA COLLECTION!
declare -A PROFILES
declare -A PROFILE_DESCRIPTIONS

# C/C++ Development
PROFILES[c]="build-essential gcc g++ gdb valgrind cmake ninja-build clang clang-format clang-tidy cppcheck doxygen libboost-all-dev autoconf automake libtool pkg-config libcmocka-dev libcmocka0 lcov libncurses5-dev libncursesw5-dev"
PROFILE_DESCRIPTIONS[c]="C/C++ Development (compilers, debuggers, analyzers, build tools, cmocka, coverage, ncurses)"

# OpenWRT Development
PROFILES[openwrt]="build-essential gcc g++ make git wget unzip sudo file python3 python3-distutils rsync libncurses5-dev zlib1g-dev gawk gettext libssl-dev xsltproc libelf-dev libtool automake autoconf ccache subversion swig time qemu-system-arm qemu-system-aarch64 qemu-system-mips qemu-system-x86 qemu-utils"
PROFILE_DESCRIPTIONS[openwrt]="OpenWRT Development (cross-compilation, QEMU, build essentials)"

# Rust Development
PROFILES[rust]="curl build-essential pkg-config libssl-dev"
PROFILE_DESCRIPTIONS[rust]="Rust Development (cargo and rustc will be installed separately)"

# Python Development
PROFILES[python]="python3 python3-pip python3-venv python3-dev build-essential libffi-dev libssl-dev python3-setuptools python3-wheel ipython3 black pylint mypy"
PROFILE_DESCRIPTIONS[python]="Python Development (Python 3, pip, venv, linters, formatters)"

# Go Development
PROFILES[go]="wget git build-essential"
PROFILE_DESCRIPTIONS[go]="Go Development (Go will be installed separately)"

# Node.js/JavaScript Development
PROFILES[javascript]="build-essential python3"
PROFILE_DESCRIPTIONS[javascript]="JavaScript/TypeScript Development (Node.js, npm, yarn)"

# Java Development
PROFILES[java]="openjdk-17-jdk maven gradle ant"
PROFILE_DESCRIPTIONS[java]="Java Development (OpenJDK 17, Maven, Gradle, Ant)"

# Ruby Development
PROFILES[ruby]="ruby-full ruby-dev build-essential zlib1g-dev libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libcurl4-openssl-dev software-properties-common libffi-dev"
PROFILE_DESCRIPTIONS[ruby]="Ruby Development (Ruby, gems, build tools)"

# PHP Development
PROFILES[php]="php php-cli php-fpm php-mysql php-pgsql php-sqlite3 php-curl php-gd php-mbstring php-xml php-zip composer"
PROFILE_DESCRIPTIONS[php]="PHP Development (PHP, Composer, common extensions)"

# Database Tools
PROFILES[database]="postgresql-client mysql-client sqlite3 redis-tools mongodb-clients"
PROFILE_DESCRIPTIONS[database]="Database Tools (PostgreSQL, MySQL, SQLite, Redis, MongoDB clients)"

# DevOps Tools
PROFILES[devops]="docker.io docker-compose kubectl helm terraform ansible awscli"
PROFILE_DESCRIPTIONS[devops]="DevOps Tools (Docker, K8s, Terraform, Ansible, AWS CLI)"

# Web Development
PROFILES[web]="nginx apache2-utils curl wget httpie jq"
PROFILE_DESCRIPTIONS[web]="Web Development Tools (nginx, curl, httpie, jq)"

# Embedded Development
PROFILES[embedded]="gcc-arm-none-eabi gdb-multiarch openocd picocom minicom screen platformio"
PROFILE_DESCRIPTIONS[embedded]="Embedded Development (ARM toolchain, debuggers, serial tools)"

# Data Science
PROFILES[datascience]="python3-numpy python3-pandas python3-scipy python3-matplotlib python3-seaborn jupyter-notebook r-base"
PROFILE_DESCRIPTIONS[datascience]="Data Science (NumPy, Pandas, Jupyter, R)"

# Security Tools
PROFILES[security]="nmap tcpdump wireshark-common netcat-openbsd john hashcat hydra"
PROFILE_DESCRIPTIONS[security]="Security Tools (network analysis, penetration testing)"

# ML/AI Development
PROFILES[ml]="python3-pip python3-dev python3-venv build-essential cmake"
PROFILE_DESCRIPTIONS[ml]="Machine Learning (base tools, Python libs installed separately)"

# Spinner function
show_spinner() {
	local pid=$1
	local msg=$2
	local spin='⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏'
	local i=0
	echo -n "$msg "
	while kill -0 $pid 2>/dev/null; do
		printf "\b%s" "${spin:i++%${#spin}:1}"
		sleep 0.1
	done
	echo -e "\b${GREEN}✓${NC}"
}

if [[ "${1:-}" == "profile" ]]; then
    shift
    if [[ $# -eq 0 ]]; then
        echo -e "${CYAN}Available Profiles:${NC}"
        echo
        for profile in $(printf '%s\n' "${!PROFILE_DESCRIPTIONS[@]}" | sort); do
            echo -e "  ${GREEN}$profile${NC} - ${PROFILE_DESCRIPTIONS[$profile]}"
        done
        echo
        echo -e "${YELLOW}Usage: claudebox profile <name> [<name2> ...]${NC}"
        echo -e "${YELLOW}Example: claudebox profile c python web${NC}"
        exit 0
    fi

    # Install selected profiles
    PACKAGES_TO_INSTALL=""
    SELECTED_PROFILES=()

    for profile in "$@"; do
        if [[ -n "${PROFILES[$profile]:-}" ]]; then
            PACKAGES_TO_INSTALL="$PACKAGES_TO_INSTALL ${PROFILES[$profile]}"
            SELECTED_PROFILES+=("$profile")
        else
            echo -e "${RED}Unknown profile: $profile${NC}"
            echo -e "${YELLOW}Run 'claudebox profile' to see available profiles${NC}"
            exit 1
        fi
    done

    echo -e "${PURPLE}Installing profiles: ${SELECTED_PROFILES[*]}${NC}"

    # Create temporary container
    TEMP_CONTAINER=$(docker create "$IMAGE_NAME" sleep infinity)
    docker start "$TEMP_CONTAINER" >/dev/null

    # Update package lists
    docker exec -u root "$TEMP_CONTAINER" apt-get update -qq >/dev/null 2>&1 &
    show_spinner $! "Updating package lists..."

    # Install packages
    docker exec -u root "$TEMP_CONTAINER" bash -c "
        export DEBIAN_FRONTEND=noninteractive
        apt-get install -y -qq $PACKAGES_TO_INSTALL >/dev/null 2>&1
    " &
    show_spinner $! "Installing packages..."

    # Special handling for language-specific tools
    for profile in "${SELECTED_PROFILES[@]}"; do
        case "$profile" in
            rust)
                docker exec -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
                    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y >/dev/null 2>&1
                    source \$HOME/.cargo/env
                    rustup component add clippy rustfmt rust-analyzer >/dev/null 2>&1
                " &
                show_spinner $! "Installing Rust toolchain..."
                ;;
            go)
                docker exec -u root "$TEMP_CONTAINER" bash -c "
                    ARCH=\$(dpkg --print-architecture)
                    case \$ARCH in
                        amd64) GOARCH=amd64 ;;
                        arm64|aarch64) GOARCH=arm64 ;;
                        armhf) GOARCH=armv6l ;;
                        *) echo 'Unsupported architecture for Go'; exit 1 ;;
                    esac
                    wget -q https://go.dev/dl/go1.21.5.linux-\${GOARCH}.tar.gz
                    tar -C /usr/local -xzf go1.21.5.linux-\${GOARCH}.tar.gz
                    rm go1.21.5.linux-\${GOARCH}.tar.gz
                    echo 'export PATH=/usr/local/go/bin:\$PATH' >> /etc/profile
                " >/dev/null 2>&1 &
                show_spinner $! "Installing Go..."
                ;;
            javascript)
                docker exec -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
                    source \$HOME/.nvm/nvm.sh
                    npm install -g typescript ts-node eslint prettier webpack vite nodemon pm2 yarn pnpm >/dev/null 2>&1
                " &
                show_spinner $! "Installing Node.js tools..."
                ;;
            python)
                docker exec -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
                    pip3 install --user pipenv poetry virtualenv pytest requests numpy pandas matplotlib jupyterlab >/dev/null 2>&1
                " &
                show_spinner $! "Installing Python tools..."
                ;;
            ml)
                docker exec -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
                    pip3 install --user torch torchvision torchaudio tensorflow scikit-learn transformers datasets >/dev/null 2>&1
                " &
                show_spinner $! "Installing ML libraries..."
                ;;
        esac
    done

    # Clean apt cache
    docker exec -u root "$TEMP_CONTAINER" bash -c "
        apt-get clean >/dev/null 2>&1
        rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
    " >/dev/null 2>&1

    # Commit changes
    docker commit "$TEMP_CONTAINER" "$IMAGE_NAME" >/dev/null &
    show_spinner $! "Saving changes to image..."

    # Cleanup
    docker rm -f "$TEMP_CONTAINER" >/dev/null

    echo -e "${GREEN}Profile installation complete!${NC}"
    exit 0
fi

# --- MCP Command Handling ---
MCP_USER_CONFIG_PATH="$HOME/.config/claude/mcp-servers-user.json" # User-specific, distinct from Claude's main config
MCP_PROJECT_CONFIG_FILENAME=".mcp.json" # Standard project-level config

get_mcp_config_path() {
    local scope="$1"
    case "$scope" in
        project)
            echo "$PROJECT_DIR/$MCP_PROJECT_CONFIG_FILENAME"
            ;;
        user)
            mkdir -p "$(dirname "$MCP_USER_CONFIG_PATH")" # Ensure directory exists
            echo "$MCP_USER_CONFIG_PATH"
            ;;
        # 'container_default' would refer to the one inside ~/.config/claude/config.json in the image
        *)
            echo -e "${RED}Error: Invalid MCP scope '$scope' provided to get_mcp_config_path.${NC}" >&2
            return 1
            ;;
    esac
    return 0
}

# Function to ensure an MCP JSON file exists and is valid
ensure_mcp_json() {
    local file_path="$1"
    if [[ ! -f "$file_path" ]]; then
        echo '{"mcpServers": {}}' > "$file_path"
    else
        # Validate if it's proper JSON and has mcpServers object
        if ! jq -e '.mcpServers' "$file_path" >/dev/null 2>&1; then
            echo -e "${YELLOW}Warning: MCP file '$file_path' is invalid or does not contain .mcpServers. Initializing with empty mcpServers.{}${NC}" >&2
            # Backup bad file before overwriting
            cp "$file_path" "${file_path}.invalid_backup_$(date +%s)"
            echo '{"mcpServers": {}}' > "$file_path"
        fi
    fi
}

handle_mcp_add() {
    local server_name=""
    local server_command=""
    local server_args_json="[]" # Default to empty JSON array
    local server_env_json="{}"  # Default to empty JSON object
    local scope="project" # Default scope

    # Parse arguments for mcp add
    # Example: claudebox mcp add <name> <command> --args '["--port","8080"]' --env '{"MY_VAR":"val"}' --scope project
    if [[ -z "${1:-}" ]]; then
        echo -e "${RED}Error: Server name is required for 'mcp add'.${NC}" >&2; exit 1;
    fi
    server_name="$1"; shift
    if [[ -z "${1:-}" ]]; then
        echo -e "${RED}Error: Server command is required for 'mcp add'.${NC}" >&2; exit 1;
    fi
    server_command="$1"; shift

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --args) server_args_json="$2"; shift 2 ;;
            --env) server_env_json="$2"; shift 2 ;;
            --scope) scope="$2"; shift 2 ;;
            *) echo -e "${RED}Unknown option for 'mcp add': $1${NC}" >&2; exit 1 ;;
        esac
    done

    if ! jq -e . >/dev/null 2>&1 <<<"$server_args_json"; then
        echo -e "${RED}Error: --args value is not valid JSON: $server_args_json${NC}" >&2; exit 1
    fi
    if ! jq -e . >/dev/null 2>&1 <<<"$server_env_json"; then
        echo -e "${RED}Error: --env value is not valid JSON: $server_env_json${NC}" >&2; exit 1
    fi

    local config_path
    config_path=$(get_mcp_config_path "$scope")
    if [[ -z "$config_path" ]]; then exit 1; fi # Error message from get_mcp_config_path

    ensure_mcp_json "$config_path"

    confirm_action 1 "Add/update MCP server '$server_name' in '$scope' scope ($config_path)." "mcp_add"

    # Use jq to add the server configuration
    jq ".mcpServers.\"$server_name\" = {
        command: \"$server_command\",
        args: $server_args_json,
        env: $server_env_json
    }" "$config_path" > "${config_path}.tmp" && mv "${config_path}.tmp" "$config_path"

    if [[ $? -eq 0 ]]; then
        echo -e "${GREEN}MCP server '$server_name' added/updated in '$scope' scope ($config_path).${NC}"
    else
        echo -e "${RED}Error: Failed to update MCP config file '$config_path'.${NC}" >&2
        rm -f "${config_path}.tmp"
        exit 1
    fi
}

handle_mcp_get() {
    local server_name="${1:-}"
    local scope_filter="${2:-effective}" # Specific scope or 'effective' to use precedence

    if [[ -z "$server_name" ]]; then
        echo -e "${RED}Error: Server name is required for 'mcp get'.${NC}" >&2; exit 1;
    fi

    echo -e "${CYAN}Getting MCP Server '$server_name' (Scope: $scope_filter):${NC}"

    local project_config_path="$PROJECT_DIR/$MCP_PROJECT_CONFIG_FILENAME"
    local user_config_path
    user_config_path=$(get_mcp_config_path "user")

    local default_servers_json='{
        "claudebox_thinking": {
            "command": "/home/'$DOCKER_USER'/mcp-servers/run-thinking.sh", "args": [], "env": {}
        },
        "claudebox_memory": {
            "command": "/home/'$DOCKER_USER'/mcp-servers/run-memory.sh", "args": [], "env": {"MEMORY_FILE_PATH": "/home/'$DOCKER_USER'/.claudebox/memory.json"}
        }
    }'
    local server_json=""
    local found_in_scope=""

    if [[ "$scope_filter" == "project" || "$scope_filter" == "effective" ]]; then
        if [[ -f "$project_config_path" ]]; then
            ensure_mcp_json "$project_config_path"
            server_json=$(jq -e ".mcpServers.\"$server_name\"" "$project_config_path" 2>/dev/null)
            if [[ -n "$server_json" && "$server_json" != "null" ]]; then
                found_in_scope="Project ($project_config_path)"
            fi
        fi
    fi

    if [[ -z "$found_in_scope" && ( "$scope_filter" == "user" || "$scope_filter" == "effective" ) ]]; then
        if [[ -f "$user_config_path" ]]; then
            ensure_mcp_json "$user_config_path"
            server_json=$(jq -e ".mcpServers.\"$server_name\"" "$user_config_path" 2>/dev/null)
            if [[ -n "$server_json" && "$server_json" != "null" ]]; then
                found_in_scope="User ($user_config_path)"
            fi
        fi
    fi

    if [[ -z "$found_in_scope" && ( "$scope_filter" == "container_default" || "$scope_filter" == "effective" ) ]]; then
        server_json=$(echo "$default_servers_json" | jq -e ".\"$server_name\"" 2>/dev/null)
        if [[ -n "$server_json" && "$server_json" != "null" ]]; then
            found_in_scope="Container Default (built-in)"
        fi
    fi

    if [[ -n "$found_in_scope" ]]; then
        echo -e "${PURPLE}Found in: $found_in_scope${NC}"
        echo "$server_json" | jq . # Pretty print
    else
        echo -e "${RED}Server '$server_name' not found in scope '$scope_filter'.${NC}"
        if [[ "$scope_filter" == "effective" ]]; then
             echo -e "${YELLOW}Searched Project, User, and Container Default scopes.${NC}"
        fi
        exit 1
    fi
}

handle_mcp_remove() {
    local server_name="${1:-}"
    local scope="${2:-}"

    if [[ -z "$server_name" ]]; then
        echo -e "${RED}Error: Server name is required for 'mcp remove'.${NC}" >&2; exit 1;
    fi
    if [[ -z "$scope" ]]; then
        echo -e "${RED}Error: --scope (project|user) is required for 'mcp remove'.${NC}" >&2; exit 1;
    fi
    if [[ "$scope" != "project" && "$scope" != "user" ]]; then
        echo -e "${RED}Error: Invalid scope '$scope'. Must be 'project' or 'user' for 'mcp remove'.${NC}" >&2; exit 1;
    fi

    local config_path
    config_path=$(get_mcp_config_path "$scope")
    if [[ -z "$config_path" ]]; then exit 1; fi

    if [[ ! -f "$config_path" ]]; then
        echo -e "${RED}Error: MCP config file '$config_path' does not exist. Nothing to remove.${NC}" >&2; exit 1;
    fi
    ensure_mcp_json "$config_path" # Validate

    # Check if server exists before trying to remove
    local server_exists
    server_exists=$(jq -e ".mcpServers.\"$server_name\"" "$config_path" 2>/dev/null)
    if [[ -z "$server_exists" || "$server_exists" == "null" ]]; then
        echo -e "${YELLOW}Warning: Server '$server_name' not found in '$config_path'. Nothing to remove.${NC}"
        exit 0
    fi

    confirm_action 1 "Remove MCP server '$server_name' from '$scope' scope ($config_path)." "mcp_remove"

    jq "del(.mcpServers.\"$server_name\")" "$config_path" > "${config_path}.tmp" && mv "${config_path}.tmp" "$config_path"

    if [[ $? -eq 0 ]]; then
        echo -e "${GREEN}MCP server '$server_name' removed from '$scope' scope ($config_path).${NC}"
    else
        echo -e "${RED}Error: Failed to update MCP config file '$config_path' during remove.${NC}" >&2
        rm -f "${config_path}.tmp"
        exit 1
    fi
}

handle_mcp_list() {
    local scope_filter="${1:-all}" # project, user, all (default)
    echo -e "${CYAN}Listing MCP Servers (Scope: $scope_filter):${NC}"

    local project_config_path="$PROJECT_DIR/$MCP_PROJECT_CONFIG_FILENAME"
    local user_config_path
    user_config_path=$(get_mcp_config_path "user") # To ensure dir exists if we need it

    # Representing claudebox default servers (which are now managed in project .mcp.json by configure_default_project_mcp)
    # For the purpose of "all" or "container_default" scope listing, we can show what claudebox *would* typically configure.
    # These names `claudebox_thinking` and `claudebox_memory` are what `configure_default_project_mcp` ensures are present.
    local default_servers_json='{
        "claudebox_thinking": {
            "command": "/home/'$DOCKER_USER'/mcp-servers/run-thinking.sh", "args": [], "env": {}
        },
        "claudebox_memory": {
            "command": "/home/'$DOCKER_USER'/mcp-servers/run-memory.sh", "args": [], "env": {"MEMORY_FILE_PATH": "/home/'$DOCKER_USER'/.claudebox/memory.json"}
        }
    }'

    output_servers() {
        local title="$1"
        local servers_json="$2"
        echo -e "${PURPLE}--- $title ---${NC}"
        if [[ -z "$servers_json" || "$servers_json" == "{}" || "$servers_json" == "null" ]]; then
            echo "  No servers configured."
            return
        fi
        echo "$servers_json" | jq -r 'to_entries[] | "  \(.key):\n    Command: \(.value.command)\n    Args: \(.value.args | tostring)\n    Env: \(.value.env | tostring)"'
    }

    declare -A combined_servers=() # Associative array to hold merged servers

    # 1. Load container defaults
    if [[ "$scope_filter" == "all" ]]; then
        while IFS="=" read -r key value; do
            combined_servers["$key"]="$value"
        done < <(echo "$default_servers_json" | jq -r 'to_entries[] | "\(.key)=\(.value|@json)"')
    fi

    # 2. Load user servers, potentially overriding defaults
    if [[ "$scope_filter" == "all" || "$scope_filter" == "user" ]]; then
        if [[ -f "$user_config_path" ]]; then
            ensure_mcp_json "$user_config_path" # Validate/initialize
            user_servers_json=$(jq '.mcpServers' "$user_config_path")
            if [[ "$user_servers_json" != "null" && "$user_servers_json" != "{}" ]]; then
                 while IFS="=" read -r key value; do
                    combined_servers["$key"]="$value"
                done < <(echo "$user_servers_json" | jq -r 'to_entries[] | "\(.key)=\(.value|@json)"')
                if [[ "$scope_filter" == "user" ]]; then output_servers "User Scoped ($user_config_path)" "$user_servers_json"; fi
            elif [[ "$scope_filter" == "user" ]]; then
                 output_servers "User Scoped ($user_config_path)" "{}"
            fi
        elif [[ "$scope_filter" == "user" ]]; then
            output_servers "User Scoped ($user_config_path - file not found)" "{}"
        fi
    fi

    # 3. Load project servers, potentially overriding user/defaults
    if [[ "$scope_filter" == "all" || "$scope_filter" == "project" ]]; then
        if [[ -f "$project_config_path" ]]; then
            ensure_mcp_json "$project_config_path" # Validate/initialize
            project_servers_json=$(jq '.mcpServers' "$project_config_path")
             if [[ "$project_servers_json" != "null" && "$project_servers_json" != "{}" ]]; then
                while IFS="=" read -r key value; do
                    combined_servers["$key"]="$value"
                done < <(echo "$project_servers_json" | jq -r 'to_entries[] | "\(.key)=\(.value|@json)"')
                if [[ "$scope_filter" == "project" ]]; then output_servers "Project Scoped ($project_config_path)" "$project_servers_json"; fi
            elif [[ "$scope_filter" == "project" ]]; then
                output_servers "Project Scoped ($project_config_path)" "{}"
            fi
        elif [[ "$scope_filter" == "project" ]]; then
            output_servers "Project Scoped ($project_config_path - file not found)" "{}"
        fi
    fi

    if [[ "$scope_filter" == "all" ]]; then
        echo -e "${PURPLE}--- Combined & Effective (Project > User > Default) ---${NC}"
        if [[ ${#combined_servers[@]} -eq 0 ]]; then
            echo "  No servers configured across any scope."
        else
            # Convert associative array back to JSON for consistent printing
            local final_json="{}"
            for key in "${!combined_servers[@]}"; do
                final_json=$(echo "$final_json" | jq ". + {\"$key\": ${combined_servers[$key]}}")
            done
            output_servers "Combined" "$final_json"
        fi
    fi
}


if [[ "${1:-}" == "mcp" ]]; then
    shift # remove 'mcp'
    local mcp_command="${1:-}"
    shift || true # remove subcommand or do nothing if no subcommand
    case "$mcp_command" in
        add)
            handle_mcp_add "$@"
            ;;
        get)
            local server_name_get="${1:-}"
            local scope_get_val="effective" # Default
            if [[ "$2" == "--scope" && -n "$3" ]]; then
                scope_get_val="$3"
            fi
            handle_mcp_get "$server_name_get" "$scope_get_val"
            ;;
        remove)
            local server_name_remove="${1:-}"
            local scope_remove_val=""
            if [[ "$2" == "--scope" && -n "$3" ]]; then
                scope_remove_val="$3"
            else
                echo -e "${RED}Error: --scope (project|user) is mandatory for 'mcp remove'.${NC}" >&2; exit 1;
            fi
            handle_mcp_remove "$server_name_remove" "$scope_remove_val"
            ;;
        list)
            local list_scope="all" # Default
            if [[ "${1:-}" == "--scope" && -n "${2:-}" ]]; then
                list_scope="$2"; shift 2;
            elif [[ -n "${1:-}" && "${1:-}" != --* ]]; then # allow `claudebox mcp list project`
                list_scope="$1"; shift;
            fi
            if [[ $# -gt 0 ]]; then echo -e "${RED}Error: Unknown arguments for 'mcp list': $@${NC}"; exit 1; fi
            handle_mcp_list "$list_scope"
            ;;
        *)
            echo -e "${RED}Unknown mcp command: ${mcp_command}${NC}" >&2
            echo "Usage: claudebox mcp [add|get|list|remove] [options]" >&2
            exit 1
            ;;
    esac
    exit 0
fi

# Other commands (install, shell, etc.)
if [[ "${1:-}" == "install" ]]; then
    shift # remove 'install'

    local packages_to_install_raw=("$@")
    local sanitized_packages_to_install=()

    if [[ ${#packages_to_install_raw[@]} -eq 0 ]]; then
        echo -e "${RED}Error: No packages specified. Usage: claudebox install <package1> <package2> ...${NC}" >&2
        exit 1
    fi

    for pkg_name in "${packages_to_install_raw[@]}"; do
        local sanitized_name
        sanitized_name=$(sanitize_input_for_command "$pkg_name")
        if [[ -n "$sanitized_name" ]]; then
            sanitized_packages_to_install+=("$sanitized_name")
        else
            echo -e "${RED}Error: Invalid package name '$pkg_name'. Contains forbidden characters or is empty.${NC}" >&2
            echo -e "${YELLOW}Allowed characters are alphanumeric, underscore, hyphen, period, colon, tilde, plus.${NC}" >&2
            exit 1
        fi
    done

    if [[ ${#sanitized_packages_to_install[@]} -eq 0 ]]; then
        # This case should ideally not be reached if the loop above exits on first invalid
        echo -e "${RED}Error: No valid package names provided after sanitization.${NC}" >&2
        exit 1
    fi

    echo "Attempting to install additional packages: ${sanitized_packages_to_install[*]}"
    confirm_action 1 "Install additional apt packages (${sanitized_packages_to_install[*]}) into the Docker image." "install_packages"

    TEMP_CONTAINER=$(docker create "$IMAGE_NAME" sleep infinity)
    docker start "$TEMP_CONTAINER" >/dev/null

    docker exec -u root "$TEMP_CONTAINER" bash -c "
        export DEBIAN_FRONTEND=noninteractive
        apt-get update -qq
        apt-get install -y -qq ${sanitized_packages_to_install[*]} 2>&1 | grep -v 'invoke-rc.d' | grep -v 'policy-rc.d' || true
        apt-get clean
        rm -rf /var/lib/apt/lists/*
    "

    docker commit "$TEMP_CONTAINER" "$IMAGE_NAME" >/dev/null
    docker rm -f "$TEMP_CONTAINER" >/dev/null

    echo "Packages installed successfully!"
    exit 0
fi

if [[ "${1:-}" == "update" ]]; then
    echo -e "${BLUE}Updating Claude code...${NC}"

    # Create temporary container
    TEMP_CONTAINER=$(docker create "$IMAGE_NAME" sleep infinity)
    docker start "$TEMP_CONTAINER" >/dev/null

    # Step 1: Run claude update to download the update
    docker exec -it -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
        source \$HOME/.nvm/nvm.sh
        nvm use default
        claude update
    "

    # Step 2: Run claude again to apply the update (simulating a restart)
    echo -e "${BLUE}Applying update...${NC}"
    docker exec -it -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
        source \$HOME/.nvm/nvm.sh
        nvm use default
        # Run claude --version to trigger the update application
        claude --version
    "
    # Commit changes back to the image
    docker commit "$TEMP_CONTAINER" "$IMAGE_NAME" >/dev/null
    docker rm -f "$TEMP_CONTAINER" >/dev/null

    echo -e "${GREEN}Claude code update completed and saved to image!${NC}"
    exit 0
fi

# Commands that need to persist changes to the image
PERSISTENT_COMMANDS="config|mcp|migrate-installer|update"

if [[ "${1:-}" =~ ^($PERSISTENT_COMMANDS)$ ]]; then
    # Ensure image exists
    if ! docker image inspect "$IMAGE_NAME" &>/dev/null; then
        echo -e "${RED}Error: ClaudeBox image not found.${NC}"
        echo -e "Run ${GREEN}claudebox${NC} first to build the image."
        exit 1
    fi

    if [[ "${1:-}" == "update" ]]; then
        TEMP_CONTAINER=$(docker create "$IMAGE_NAME" sleep infinity)
        docker start "$TEMP_CONTAINER" >/dev/null

        docker exec -it -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
            source \$HOME/.nvm/nvm.sh
            nvm use default
            claude update"

        docker exec -it -u "$DOCKER_USER" "$TEMP_CONTAINER" bash -c "
            source \$HOME/.nvm/nvm.sh
            nvm use default
            claude --version"

        docker commit "$TEMP_CONTAINER" "$IMAGE_NAME" >/dev/null
        docker rm -f "$TEMP_CONTAINER" >/dev/null
    else
        # Other commands - just run them
        TEMP_CONTAINER=$(docker create "$IMAGE_NAME" sleep infinity)
        docker start "$TEMP_CONTAINER" >/dev/null

        docker exec -it -u "$DOCKER_USER" "$TEMP_CONTAINER" \
            /home/$DOCKER_USER/claude-wrapper "$@"
        docker commit "$TEMP_CONTAINER" "$IMAGE_NAME" >/dev/null
        docker rm -f "$TEMP_CONTAINER" >/dev/null
    fi
    exit 0
fi


if [[ "${1:-}" == "shell" ]]; then
    docker run -it --rm \
        -u "$DOCKER_USER" \
        -w /workspace \
        -v "$PROJECT_DIR":/workspace \
        -v "$CLAUDE_DATA_DIR":/home/$DOCKER_USER/.claude \
        -v "$HOME/.claudebox":/home/$DOCKER_USER/.claudebox \
        -v "$HOME/.config/claude":/home/$DOCKER_USER/.config/claude \
        -v "$HOME/.claude.json":/home/$DOCKER_USER/.claude.json \
        -v "$HOME/.npmrc":/home/$DOCKER_USER/.npmrc:ro \
        -v "$HOME/.ssh":/home/$DOCKER_USER/.ssh:ro \
        -e "NODE_ENV=${NODE_ENV:-production}" \
        -e "ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}" \
        --cap-add NET_ADMIN \
        --cap-add NET_RAW \
        --entrypoint /bin/bash \
        "$IMAGE_NAME"
    exit 0
fi

if [[ "${1:-}" == "clean" ]]; then
    shift
    if [[ "${1:-}" == "--all" || "${1:-}" == "-a" ]]; then
        confirm_action 2 "Deep clean ClaudeBox: Remove Docker image '$IMAGE_NAME' and ALL Docker build cache. This is highly destructive and may affect other Docker builds on your system." "clean_all_cache"
        echo -e "${BLUE}Proceeding with deep clean...${NC}"
        docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
        docker builder prune -af
        echo -e "${GREEN}Deep clean complete!${NC}"
    else
        confirm_action 1 "Clean ClaudeBox: Remove Docker image '$IMAGE_NAME' and dangling build cache." "clean_image"
        echo -e "${BLUE}Proceeding with clean...${NC}"
        docker rmi -f "$IMAGE_NAME" 2>/dev/null || true
        docker builder prune -f
        echo -e "${GREEN}Clean complete!${NC}"
    fi
    docker system df
    exit 0
fi

if [[ "${1:-}" == "help" || "${1:-}" == "--help" || "${1:-}" == "-h" ]]; then
    # --help or -h -> show Claude's help
    if docker image inspect "$IMAGE_NAME" &>/dev/null; then
        docker run --rm \
            -u "$DOCKER_USER" \
            --entrypoint /home/$DOCKER_USER/claude-wrapper \
            "$IMAGE_NAME" --help | sed '1s/claude/claudebox/g'
        echo
        echo -e "${WHITE}Added Options:${NC}"
        echo -e "${CYAN}  --dangerously-enable-sudo       ${WHITE}Enable NOPASSWD sudo for the container user *inside* the container."
        echo -e "${CYAN}                                    ${RED}Use with extreme caution.${NC}"
        echo -e "${CYAN}  --dangerously-disable-firewall  ${WHITE}Disable the container's network firewall (allows all outbound connections)."
        echo -e "${CYAN}                                    ${RED}Use with extreme caution.${NC}"
        echo -e "${CYAN}  --dangerously-skip-permissions  ${WHITE}Pass directly to 'claude' CLI; may bypass certain Claude CLI safety checks."
        echo
        echo -e "${WHITE}Added Commands:${NC}"
        echo -e "  profile [names...]              Install language profiles into the image."
        echo -e "  install <pkgs...>               Install apt packages into the image. Package names are sanitized."
        echo -e "  mcp <add|get|list|remove>       Manage MCP server configurations."
        echo -e "  shell                           Open a bash shell in the container."
        echo -e "  info                            Show ClaudeBox information (TODO)."
        echo -e "  clean [--all]                   Remove ClaudeBox image (and optionally all Docker build cache)."
        echo -e "  rebuild                         Rebuild Docker image from scratch."
        echo
        echo -e "${WHITE}Security Considerations:${NC}"
        echo -e "  - Operations requiring 'sudo' on the host (like initial Docker setup or symlink creation)"
        echo -e "    will prompt for confirmation, requiring you to type a keyword."
        echo -e "  - Modifying the Docker image (profiles, install) will prompt for y/N confirmation."
        echo -e "  - Use '--dangerously-*' flags with full understanding of their implications."
        echo -e "  - MCP server commands are defined by you; ensure they are from trusted sources or are safe."
        echo -e "  - Package names for 'claudebox install' are sanitized to prevent command injection."
        echo -e "  - For more details, review the script and Dockerfile contents."
        echo
        echo -e "${WHITE}Environment Variables for Automation:${NC}"
        echo -e "  ${CYAN}CLAUDEBOX_AUTO_APPROVE_TIER1=true${NC}          ${WHITE}Auto-approve Tier 1 confirmations (y/N prompts).${NC}"
        echo -e "  ${CYAN}CLAUDEBOX_AUTO_APPROVE_TIER2_DANGEROUS=true${NC} ${WHITE}Auto-approve Tier 2 confirmations (keyword prompts). ${RED}Highly risky, use with care.${NC}"
        echo
    else
        echo -e "${CYAN}ClaudeBox - Claude Code Docker Environment${NC}"
        echo
        echo -e "${YELLOW}First run setup required!${NC}"
        echo "Run script without arguments first to build the Docker image."
        echo
    fi
    exit 0
fi

if [[ "${1:-}" == "rebuild" ]]; then
    confirm_action 2 "Rebuild ClaudeBox: This will first attempt to remove the existing Docker image '$IMAGE_NAME' (if it exists) and then build a new one." "rebuild_image"
    echo -e "${BLUE}Proceeding with rebuild...${NC}"
    if docker image inspect "$IMAGE_NAME" &>/dev/null; then
        echo -e "${YELLOW}Attempting to remove existing image '$IMAGE_NAME'...${NC}"
        docker rmi -f "$IMAGE_NAME" 2>/dev/null || true &
        show_spinner $! "Removing existing image..."
        echo -e "${GREEN}Finished attempt to remove existing image.${NC}"
    else
        echo -e "${BLUE}Image '$IMAGE_NAME' not found, no removal needed before rebuild.${NC}"
    fi
    # The actual build will be triggered by the standard image check logic later
fi

mkdir -p "$CLAUDE_DATA_DIR"
mkdir -p "$HOME/.claudebox"

# Handle ClaudeBox default MCP server configuration in project .mcp.json
# This needs to be smarter: only add claudebox defaults if they are missing,
# and don't destroy user-added servers.
configure_default_project_mcp() {
    local project_mcp_file="$PROJECT_DIR/$MCP_PROJECT_CONFIG_FILENAME"
    local claudebox_thinking_server_name="claudebox_thinking"
    local claudebox_memory_server_name="claudebox_memory"
    
    local expected_thinking_cmd="/home/$DOCKER_USER/mcp-servers/run-thinking.sh"
    local expected_memory_cmd="/home/$DOCKER_USER/mcp-servers/run-memory.sh"
    local memory_env_json="{\"MEMORY_FILE_PATH\": \"/home/$DOCKER_USER/.claudebox/memory.json\"}"

    ensure_mcp_json "$project_mcp_file" # Ensure file exists and is valid JSON

    local current_config_json
    current_config_json=$(cat "$project_mcp_file")

    # Check if claudebox_thinking is missing or incorrect
    if ! echo "$current_config_json" | jq -e ".mcpServers.\"$claudebox_thinking_server_name\" | select(.command == \"$expected_thinking_cmd\")" > /dev/null 2>&1; then
        echo "$current_config_json" | jq ".mcpServers.\"$claudebox_thinking_server_name\" = {command: \"$expected_thinking_cmd\", args: [], env: {}}" > "${project_mcp_file}.tmp" && mv "${project_mcp_file}.tmp" "$project_mcp_file"
        current_config_json=$(cat "$project_mcp_file") # Reload
        echo -e "${BLUE}Configured default '$claudebox_thinking_server_name' in $project_mcp_file${NC}"
    fi

    # Check if claudebox_memory is missing or incorrect
    if ! echo "$current_config_json" | jq -e ".mcpServers.\"$claudebox_memory_server_name\" | select(.command == \"$expected_memory_cmd\" and .env == $memory_env_json)" > /dev/null 2>&1; then
         echo "$current_config_json" | jq ".mcpServers.\"$claudebox_memory_server_name\" = {command: \"$expected_memory_cmd\", args: [], env: $memory_env_json}" > "${project_mcp_file}.tmp" && mv "${project_mcp_file}.tmp" "$project_mcp_file"
        echo -e "${BLUE}Configured default '$claudebox_memory_server_name' in $project_mcp_file${NC}"
    fi
}

# Only run default MCP configuration if not an MCP command itself
if [[ "${USER_ARGS[0]:-}" != "mcp" ]]; then
    # The old trap logic for .mcp.json backup/restore is removed.
    # ClaudeBox will now directly manage its named default servers within the project .mcp.json.
    # Users can add their own servers, and claudebox will ensure its defaults are present without clobbering others.
    configure_default_project_mcp
fi


# Check if image exists
first_time=false
if ! docker image inspect "$IMAGE_NAME" >/dev/null 2>&1; then
    logo

cat > "$DOCKERFILE" <<'EOF'
FROM debian:bookworm

ARG USER_ID
ARG GROUP_ID
ARG USERNAME
ARG NODE_VERSION

# Prevent service startup in Docker
RUN echo '#!/bin/sh\nexit 101' > /usr/sbin/policy-rc.d && \
    chmod +x /usr/sbin/policy-rc.d

# Install base dependencies
RUN export DEBIAN_FRONTEND=noninteractive && \
    apt-get update -qq && \
    apt-get install -y -qq \
    curl gnupg ca-certificates sudo git iptables ipset \
    && apt-get clean

# Create user with matching UID/GID
RUN groupadd -g $GROUP_ID $USERNAME || true \
    && useradd -m -u $USER_ID -g $GROUP_ID -s /bin/bash $USERNAME

# Install basic development tools
RUN export DEBIAN_FRONTEND=noninteractive && \
    apt-get update -qq && \
    apt-get install -y -qq \
    build-essential git wget curl unzip file vim nano \
    jq make less rsync openssh-client \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Switch to user for NVM installation
USER $USERNAME
WORKDIR /home/$USERNAME

# Install NVM
ENV NVM_DIR="/home/$USERNAME/.nvm"
RUN curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash

RUN bash -c "source $NVM_DIR/nvm.sh && \
    if [[ \"$NODE_VERSION\" == '--lts' ]]; then \
        nvm install --lts && \
        nvm alias default 'lts/*'; \
    else \
        nvm install $NODE_VERSION && \
        nvm alias default $NODE_VERSION; \
    fi && \
    nvm use default"

# Add NVM to bashrc for persistence
RUN echo 'export NVM_DIR="$HOME/.nvm"' >> ~/.bashrc && \
    echo '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' >> ~/.bashrc && \
    echo '[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"' >> ~/.bashrc

# Install Claude CLI using NVM's node
RUN bash -c "source $NVM_DIR/nvm.sh && \
    nvm use default && \
    npm install -g @anthropic-ai/claude-code"

# Install MCP SDK dependencies
RUN bash -c "source $NVM_DIR/nvm.sh && \
    nvm use default && \
    npm install @modelcontextprotocol/sdk chalk"

# Create proper MCP server packages with TypeScript compilation
RUN mkdir -p ~/mcp-servers/thinking ~/mcp-servers/memory

# Create package.json for thinking server
RUN cat > ~/mcp-servers/thinking/package.json << 'PACKAGEEOF'
{
  "name": "@modelcontextprotocol/server-sequential-thinking",
  "version": "0.6.2",
  "description": "MCP server for sequential thinking and problem solving",
  "license": "MIT",
  "type": "module",
  "bin": {
    "mcp-server-sequential-thinking": "dist/index.js"
  },
  "files": ["dist"],
  "scripts": {
    "build": "tsc && chmod +x dist/*.js",
    "prepare": "npm run build"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "0.5.0",
    "chalk": "^5.3.0"
  },
  "devDependencies": {
    "@types/node": "^22",
    "typescript": "^5.3.3"
  }
}
PACKAGEEOF

# Create tsconfig.json for thinking server
RUN cat > ~/mcp-servers/thinking/tsconfig.json << 'TSCONFIGEOF'
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./dist",
    "rootDir": ".",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  },
  "include": ["./**/*.ts"]
}
TSCONFIGEOF

# Create the TypeScript source file for thinking server
RUN cat > ~/mcp-servers/thinking/index.ts << 'THINKEOF'
#!/usr/bin/env node

import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
  Tool,
} from "@modelcontextprotocol/sdk/types.js";
import chalk from 'chalk';

interface ThoughtData {
  thought: string;
  thoughtNumber: number;
  totalThoughts: number;
  isRevision?: boolean;
  revisesThought?: number;
  branchFromThought?: number;
  branchId?: string;
  needsMoreThoughts?: boolean;
  nextThoughtNeeded: boolean;
}

class SequentialThinkingServer {
  private thoughtHistory: ThoughtData[] = [];
  private branches: Record<string, ThoughtData[]> = {};

  private validateThoughtData(input: unknown): ThoughtData {
    const data = input as Record<string, unknown>;

    if (!data.thought || typeof data.thought !== 'string') {
      throw new Error('Invalid thought: must be a string');
    }
    if (!data.thoughtNumber || typeof data.thoughtNumber !== 'number') {
      throw new Error('Invalid thoughtNumber: must be a number');
    }
    if (!data.totalThoughts || typeof data.totalThoughts !== 'number') {
      throw new Error('Invalid totalThoughts: must be a number');
    }
    if (typeof data.nextThoughtNeeded !== 'boolean') {
      throw new Error('Invalid nextThoughtNeeded: must be a boolean');
    }

    return {
      thought: data.thought,
      thoughtNumber: data.thoughtNumber,
      totalThoughts: data.totalThoughts,
      nextThoughtNeeded: data.nextThoughtNeeded,
      isRevision: data.isRevision as boolean | undefined,
      revisesThought: data.revisesThought as number | undefined,
      branchFromThought: data.branchFromThought as number | undefined,
      branchId: data.branchId as string | undefined,
      needsMoreThoughts: data.needsMoreThoughts as boolean | undefined,
    };
  }

  private formatThought(thoughtData: ThoughtData): string {
    const { thoughtNumber, totalThoughts, thought, isRevision, revisesThought, branchFromThought, branchId } = thoughtData;

    let prefix = '';
    let context = '';

    if (isRevision) {
      prefix = chalk.yellow('🔄 Revision');
      context = ` (revising thought ${revisesThought})`;
    } else if (branchFromThought) {
      prefix = chalk.green('🌿 Branch');
      context = ` (from thought ${branchFromThought}, ID: ${branchId})`;
    } else {
      prefix = chalk.blue('💭 Thought');
      context = '';
    }

    const header = `${prefix} ${thoughtNumber}/${totalThoughts}${context}`;
    const border = '─'.repeat(Math.max(header.length, thought.length) + 4);

    return `
┌${border}┐
│ ${header} │
├${border}┤
│ ${thought.padEnd(border.length - 2)} │
└${border}┘`;
  }

  public processThought(input: unknown): { content: Array<{ type: string; text: string }>; isError?: boolean } {
    try {
      const validatedInput = this.validateThoughtData(input);

      if (validatedInput.thoughtNumber > validatedInput.totalThoughts) {
        validatedInput.totalThoughts = validatedInput.thoughtNumber;
      }

      this.thoughtHistory.push(validatedInput);

      if (validatedInput.branchFromThought && validatedInput.branchId) {
        if (!this.branches[validatedInput.branchId]) {
          this.branches[validatedInput.branchId] = [];
        }
        this.branches[validatedInput.branchId].push(validatedInput);
      }

      const formattedThought = this.formatThought(validatedInput);
      console.error(formattedThought);

      return {
        content: [{
          type: "text",
          text: JSON.stringify({
            thoughtNumber: validatedInput.thoughtNumber,
            totalThoughts: validatedInput.totalThoughts,
            nextThoughtNeeded: validatedInput.nextThoughtNeeded,
            branches: Object.keys(this.branches),
            thoughtHistoryLength: this.thoughtHistory.length
          }, null, 2)
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: "text",
          text: JSON.stringify({
            error: error instanceof Error ? error.message : String(error),
            status: 'failed'
          }, null, 2)
        }],
        isError: true
      };
    }
  }
}

const SEQUENTIAL_THINKING_TOOL: Tool = {
  name: "sequentialthinking",
  description: `A detailed tool for dynamic and reflective problem-solving through thoughts.
This tool helps analyze problems through a flexible thinking process that can adapt and evolve.
Each thought can build on, question, or revise previous insights as understanding deepens.

When to use this tool:
- Breaking down complex problems into steps
- Planning and design with room for revision
- Analysis that might need course correction
- Problems where the full scope might not be clear initially
- Problems that require a multi-step solution
- Tasks that need to maintain context over multiple steps
- Situations where irrelevant information needs to be filtered out

Key features:
- You can adjust total_thoughts up or down as you progress
- You can question or revise previous thoughts
- You can add more thoughts even after reaching what seemed like the end
- You can express uncertainty and explore alternative approaches
- Not every thought needs to build linearly - you can branch or backtrack
- Generates a solution hypothesis
- Verifies the hypothesis based on the Chain of Thought steps
- Repeats the process until satisfied
- Provides a correct answer

Parameters explained:
- thought: Your current thinking step, which can include:
  * Regular analytical steps
  * Revisions of previous thoughts
  * Questions about previous decisions
  * Realizations about needing more analysis
  * Changes in approach
  * Hypothesis generation
  * Hypothesis verification
- next_thought_needed: True if you need more thinking, even if at what seemed like the end
- thought_number: Current number in sequence (can go beyond initial total if needed)
- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)
- is_revision: A boolean indicating if this thought revises previous thinking
- revises_thought: If is_revision is true, which thought number is being reconsidered
- branch_from_thought: If branching, which thought number is the branching point
- branch_id: Identifier for the current branch (if any)
- needs_more_thoughts: If reaching end but realizing more thoughts needed

You should:
1. Start with an initial estimate of needed thoughts, but be ready to adjust
2. Feel free to question or revise previous thoughts
3. Don't hesitate to add more thoughts if needed, even at the "end"
4. Express uncertainty when present
5. Mark thoughts that revise previous thinking or branch into new paths
6. Ignore information that is irrelevant to the current step
7. Generate a solution hypothesis when appropriate
8. Verify the hypothesis based on the Chain of Thought steps
9. Repeat the process until satisfied with the solution
10. Provide a single, ideally correct answer as the final output
11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached`,
  inputSchema: {
    type: "object",
    properties: {
      thought: {
        type: "string",
        description: "Your current thinking step"
      },
      nextThoughtNeeded: {
        type: "boolean",
        description: "Whether another thought step is needed"
      },
      thoughtNumber: {
        type: "integer",
        description: "Current thought number",
        minimum: 1
      },
      totalThoughts: {
        type: "integer",
        description: "Estimated total thoughts needed",
        minimum: 1
      },
      isRevision: {
        type: "boolean",
        description: "Whether this revises previous thinking"
      },
      revisesThought: {
        type: "integer",
        description: "Which thought is being reconsidered",
        minimum: 1
      },
      branchFromThought: {
        type: "integer",
        description: "Branching point thought number",
        minimum: 1
      },
      branchId: {
        type: "string",
        description: "Branch identifier"
      },
      needsMoreThoughts: {
        type: "boolean",
        description: "If more thoughts are needed"
      }
    },
    required: ["thought", "nextThoughtNeeded", "thoughtNumber", "totalThoughts"]
  }
};

const server = new Server(
  {
    name: "sequential-thinking-server",
    version: "0.2.0",
  },
  {
    capabilities: {
      tools: {},
    },
  }
);

const thinkingServer = new SequentialThinkingServer();

server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: [SEQUENTIAL_THINKING_TOOL],
}));

server.setRequestHandler(CallToolRequestSchema, async (request) => {
  if (request.params.name === "sequentialthinking") {
    return thinkingServer.processThought(request.params.arguments);
  }

  return {
    content: [{
      type: "text",
      text: `Unknown tool: ${request.params.name}`
    }],
    isError: true
  };
});

async function runServer() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("Sequential Thinking MCP Server running on stdio");
}

runServer().catch((error) => {
  console.error("Fatal error running server:", error);
  process.exit(1);
});
THINKEOF

# Create package.json for memory server
RUN cat > ~/mcp-servers/memory/package.json << 'PACKAGEEOF'
{
  "name": "@modelcontextprotocol/server-memory",
  "version": "0.6.3",
  "description": "MCP server for enabling memory for Claude through a knowledge graph",
  "license": "MIT",
  "type": "module",
  "bin": {
    "mcp-server-memory": "dist/index.js"
  },
  "files": ["dist"],
  "scripts": {
    "build": "tsc && chmod +x dist/*.js",
    "prepare": "npm run build"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "1.0.1"
  },
  "devDependencies": {
    "@types/node": "^22",
    "typescript": "^5.6.2"
  }
}
PACKAGEEOF

# Create tsconfig.json for memory server
RUN cat > ~/mcp-servers/memory/tsconfig.json << 'TSCONFIGEOF'
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./dist",
    "rootDir": ".",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  },
  "include": ["./**/*.ts"]
}
TSCONFIGEOF

# Create the TypeScript source file for memory server
RUN cat > ~/mcp-servers/memory/index.ts << 'MEMORYEOF'
#!/usr/bin/env node

import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from "@modelcontextprotocol/sdk/types.js";
import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const defaultMemoryPath = path.join(path.dirname(fileURLToPath(import.meta.url)), 'memory.json');

const MEMORY_FILE_PATH = process.env.MEMORY_FILE_PATH
  ? path.isAbsolute(process.env.MEMORY_FILE_PATH)
    ? process.env.MEMORY_FILE_PATH
    : path.join(path.dirname(fileURLToPath(import.meta.url)), process.env.MEMORY_FILE_PATH)
  : defaultMemoryPath;

interface Entity {
  name: string;
  entityType: string;
  observations: string[];
}

interface Relation {
  from: string;
  to: string;
  relationType: string;
}

interface KnowledgeGraph {
  entities: Entity[];
  relations: Relation[];
}

class KnowledgeGraphManager {
  private async loadGraph(): Promise<KnowledgeGraph> {
    try {
      const data = await fs.readFile(MEMORY_FILE_PATH, "utf-8");
      const lines = data.split("\n").filter(line => line.trim() !== "");
      return lines.reduce((graph: KnowledgeGraph, line) => {
        const item = JSON.parse(line);
        if (item.type === "entity") graph.entities.push(item as Entity);
        if (item.type === "relation") graph.relations.push(item as Relation);
        return graph;
      }, { entities: [], relations: [] });
    } catch (error) {
      if (error instanceof Error && 'code' in error && (error as any).code === "ENOENT") {
        return { entities: [], relations: [] };
      }
      throw error;
    }
  }

  private async saveGraph(graph: KnowledgeGraph): Promise<void> {
    const lines = [
      ...graph.entities.map(e => JSON.stringify({ type: "entity", ...e })),
      ...graph.relations.map(r => JSON.stringify({ type: "relation", ...r })),
    ];
    await fs.writeFile(MEMORY_FILE_PATH, lines.join("\n"));
  }

  async createEntities(entities: Entity[]): Promise<Entity[]> {
    const graph = await this.loadGraph();
    const newEntities = entities.filter(e => !graph.entities.some(existingEntity => existingEntity.name === e.name));
    graph.entities.push(...newEntities);
    await this.saveGraph(graph);
    return newEntities;
  }

  async createRelations(relations: Relation[]): Promise<Relation[]> {
    const graph = await this.loadGraph();
    const newRelations = relations.filter(r => !graph.relations.some(existingRelation =>
      existingRelation.from === r.from &&
      existingRelation.to === r.to &&
      existingRelation.relationType === r.relationType
    ));
    graph.relations.push(...newRelations);
    await this.saveGraph(graph);
    return newRelations;
  }

  async addObservations(observations: { entityName: string; contents: string[] }[]): Promise<{ entityName: string; addedObservations: string[] }[]> {
    const graph = await this.loadGraph();
    const results = observations.map(o => {
      const entity = graph.entities.find(e => e.name === o.entityName);
      if (!entity) {
        throw new Error(`Entity with name ${o.entityName} not found`);
      }
      const newObservations = o.contents.filter(content => !entity.observations.includes(content));
      entity.observations.push(...newObservations);
      return { entityName: o.entityName, addedObservations: newObservations };
    });
    await this.saveGraph(graph);
    return results;
  }

  async deleteEntities(entityNames: string[]): Promise<void> {
    const graph = await this.loadGraph();
    graph.entities = graph.entities.filter(e => !entityNames.includes(e.name));
    graph.relations = graph.relations.filter(r => !entityNames.includes(r.from) && !entityNames.includes(r.to));
    await this.saveGraph(graph);
  }

  async deleteObservations(deletions: { entityName: string; observations: string[] }[]): Promise<void> {
    const graph = await this.loadGraph();
    deletions.forEach(d => {
      const entity = graph.entities.find(e => e.name === d.entityName);
      if (entity) {
        entity.observations = entity.observations.filter(o => !d.observations.includes(o));
      }
    });
    await this.saveGraph(graph);
  }

  async deleteRelations(relations: Relation[]): Promise<void> {
    const graph = await this.loadGraph();
    graph.relations = graph.relations.filter(r => !relations.some(delRelation =>
      r.from === delRelation.from &&
      r.to === delRelation.to &&
      r.relationType === delRelation.relationType
    ));
    await this.saveGraph(graph);
  }

  async readGraph(): Promise<KnowledgeGraph> {
    return this.loadGraph();
  }

  async searchNodes(query: string): Promise<KnowledgeGraph> {
    const graph = await this.loadGraph();

    const filteredEntities = graph.entities.filter(e =>
      e.name.toLowerCase().includes(query.toLowerCase()) ||
      e.entityType.toLowerCase().includes(query.toLowerCase()) ||
      e.observations.some(o => o.toLowerCase().includes(query.toLowerCase()))
    );

    const filteredEntityNames = new Set(filteredEntities.map(e => e.name));

    const filteredRelations = graph.relations.filter(r =>
      filteredEntityNames.has(r.from) && filteredEntityNames.has(r.to)
    );

    const filteredGraph: KnowledgeGraph = {
      entities: filteredEntities,
      relations: filteredRelations,
    };

    return filteredGraph;
  }

  async openNodes(names: string[]): Promise<KnowledgeGraph> {
    const graph = await this.loadGraph();

    const filteredEntities = graph.entities.filter(e => names.includes(e.name));

    const filteredEntityNames = new Set(filteredEntities.map(e => e.name));

    const filteredRelations = graph.relations.filter(r =>
      filteredEntityNames.has(r.from) && filteredEntityNames.has(r.to)
    );

    const filteredGraph: KnowledgeGraph = {
      entities: filteredEntities,
      relations: filteredRelations,
    };

    return filteredGraph;
  }
}

const knowledgeGraphManager = new KnowledgeGraphManager();

const server = new Server({
  name: "memory-server",
  version: "0.6.3",
}, {
  capabilities: {
    tools: {},
  },
});

server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: "create_entities",
        description: "Create multiple new entities in the knowledge graph",
        inputSchema: {
          type: "object",
          properties: {
            entities: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  name: { type: "string", description: "The name of the entity" },
                  entityType: { type: "string", description: "The type of the entity" },
                  observations: {
                    type: "array",
                    items: { type: "string" },
                    description: "An array of observation contents associated with the entity"
                  },
                },
                required: ["name", "entityType", "observations"],
              },
            },
          },
          required: ["entities"],
        },
      },
      {
        name: "create_relations",
        description: "Create multiple new relations between entities in the knowledge graph. Relations should be in active voice",
        inputSchema: {
          type: "object",
          properties: {
            relations: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  from: { type: "string", description: "The name of the entity where the relation starts" },
                  to: { type: "string", description: "The name of the entity where the relation ends" },
                  relationType: { type: "string", description: "The type of the relation" },
                },
                required: ["from", "to", "relationType"],
              },
            },
          },
          required: ["relations"],
        },
      },
      {
        name: "add_observations",
        description: "Add new observations to existing entities in the knowledge graph",
        inputSchema: {
          type: "object",
          properties: {
            observations: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  entityName: { type: "string", description: "The name of the entity to add the observations to" },
                  contents: {
                    type: "array",
                    items: { type: "string" },
                    description: "An array of observation contents to add"
                  },
                },
                required: ["entityName", "contents"],
              },
            },
          },
          required: ["observations"],
        },
      },
      {
        name: "delete_entities",
        description: "Delete multiple entities and their associated relations from the knowledge graph",
        inputSchema: {
          type: "object",
          properties: {
            entityNames: {
              type: "array",
              items: { type: "string" },
              description: "An array of entity names to delete"
            },
          },
          required: ["entityNames"],
        },
      },
      {
        name: "delete_observations",
        description: "Delete specific observations from entities in the knowledge graph",
        inputSchema: {
          type: "object",
          properties: {
            deletions: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  entityName: { type: "string", description: "The name of the entity containing the observations" },
                  observations: {
                    type: "array",
                    items: { type: "string" },
                    description: "An array of observations to delete"
                  },
                },
                required: ["entityName", "observations"],
              },
            },
          },
          required: ["deletions"],
        },
      },
      {
        name: "delete_relations",
        description: "Delete multiple relations from the knowledge graph",
        inputSchema: {
          type: "object",
          properties: {
            relations: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  from: { type: "string", description: "The name of the entity where the relation starts" },
                  to: { type: "string", description: "The name of the entity where the relation ends" },
                  relationType: { type: "string", description: "The type of the relation" },
                },
                required: ["from", "to", "relationType"],
              },
              description: "An array of relations to delete"
            },
          },
          required: ["relations"],
        },
      },
      {
        name: "read_graph",
        description: "Read the entire knowledge graph",
        inputSchema: {
          type: "object",
          properties: {},
        },
      },
      {
        name: "search_nodes",
        description: "Search for nodes in the knowledge graph based on a query",
        inputSchema: {
          type: "object",
          properties: {
            query: { type: "string", description: "The search query to match against entity names, types, and observation content" },
          },
          required: ["query"],
        },
      },
      {
        name: "open_nodes",
        description: "Open specific nodes in the knowledge graph by their names",
        inputSchema: {
          type: "object",
          properties: {
            names: {
              type: "array",
              items: { type: "string" },
              description: "An array of entity names to retrieve",
            },
          },
          required: ["names"],
        },
      },
    ],
  };
});

server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;

  if (!args) {
    throw new Error(`No arguments provided for tool: ${name}`);
  }

  switch (name) {
    case "create_entities":
      return { content: [{ type: "text", text: JSON.stringify(await knowledgeGraphManager.createEntities(args.entities as Entity[]), null, 2) }] };
    case "create_relations":
      return { content: [{ type: "text", text: JSON.stringify(await knowledgeGraphManager.createRelations(args.relations as Relation[]), null, 2) }] };
    case "add_observations":
      return { content: [{ type: "text", text: JSON.stringify(await knowledgeGraphManager.addObservations(args.observations as { entityName: string; contents: string[] }[]), null, 2) }] };
    case "delete_entities":
      await knowledgeGraphManager.deleteEntities(args.entityNames as string[]);
      return { content: [{ type: "text", text: "Entities deleted successfully" }] };
    case "delete_observations":
      await knowledgeGraphManager.deleteObservations(args.deletions as { entityName: string; observations: string[] }[]);
      return { content: [{ type: "text", text: "Observations deleted successfully" }] };
    case "delete_relations":
      await knowledgeGraphManager.deleteRelations(args.relations as Relation[]);
      return { content: [{ type: "text", text: "Relations deleted successfully" }] };
    case "read_graph":
      return { content: [{ type: "text", text: JSON.stringify(await knowledgeGraphManager.readGraph(), null, 2) }] };
    case "search_nodes":
      return { content: [{ type: "text", text: JSON.stringify(await knowledgeGraphManager.searchNodes(args.query as string), null, 2) }] };
    case "open_nodes":
      return { content: [{ type: "text", text: JSON.stringify(await knowledgeGraphManager.openNodes(args.names as string[]), null, 2) }] };
    default:
      throw new Error(`Unknown tool: ${name}`);
  }
});

async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("Knowledge Graph MCP Server running on stdio");
}

main().catch((error) => {
  console.error("Fatal error in main():", error);
  process.exit(1);
});
MEMORYEOF

RUN bash -c "source $NVM_DIR/nvm.sh && \
    cd ~/mcp-servers/thinking && \
    npm install && \
    npm run build && \
    cd ~/mcp-servers/memory && \
    npm install && \
    npm run build"

RUN cat > ~/mcp-servers/run-thinking.sh << 'WRAPPEREOF'
#!/bin/bash
echo "Starting thinking server..." >&2
echo "PATH: $PATH" >&2
echo "Node version:" >&2
node --version >&2

source $HOME/.nvm/nvm.sh
nvm use default >/dev/null 2>&1

echo "After NVM setup:" >&2
which node >&2
node --version >&2

cd $HOME/mcp-servers/thinking
exec node $HOME/mcp-servers/thinking/dist/index.js "$@"
WRAPPEREOF

RUN cat > ~/mcp-servers/run-memory.sh << 'WRAPPEREOF'
#!/bin/bash
echo "Starting memory server..." >&2
echo "PATH: $PATH" >&2
echo "Node version:" >&2
node --version >&2

source $HOME/.nvm/nvm.sh
nvm use default >/dev/null 2>&1

echo "After NVM setup:" >&2
which node >&2
node --version >&2

cd $HOME/mcp-servers/memory
exec node $HOME/mcp-servers/memory/dist/index.js "$@"
WRAPPEREOF

RUN chmod +x ~/mcp-servers/thinking/dist/*.js ~/mcp-servers/memory/dist/*.js ~/mcp-servers/run-thinking.sh ~/mcp-servers/run-memory.sh

# Add this to the Dockerfile
RUN cat > ~/test-mcp.sh << 'TESTEOF'
#!/bin/bash
echo "Testing MCP servers..."

# Test thinking server
echo "Testing thinking server..."
if timeout 2 $HOME/mcp-servers/run-thinking.sh 2>&1 | grep -q "Sequential Thinking MCP Server running on stdio"; then
    echo "✓ Thinking server started successfully"
else
    echo "✗ Thinking server failed to start"
fi


# Test memory server
echo "Testing memory server..."
if timeout 2 $HOME/mcp-servers/run-memory.sh 2>&1 | grep -q "Knowledge Graph MCP Server running on stdio"; then
    echo "✓ Memory server started successfully"
else
    echo "✗ Memory server failed to start"
fi

# Check Claude config
echo "Claude MCP config:"
cat ~/.config/claude/config.json
TESTEOF

RUN chmod +x ~/test-mcp.sh

RUN cat > ~/init-firewall.sh << 'FIREWALLEOF'
#!/bin/bash
set -euo pipefail

if [ "${DISABLE_FIREWALL:-false}" = "true" ]; then
    echo "Firewall disabled, skipping setup"
    rm -f "$0"
    exit 0
fi

iptables -F OUTPUT 2>/dev/null || true
iptables -F INPUT 2>/dev/null || true

iptables -A OUTPUT -p udp --dport 53 -j ACCEPT
iptables -A OUTPUT -p tcp --dport 53 -j ACCEPT
iptables -A INPUT -p udp --sport 53 -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT
iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -s 127.0.0.0/8 -d 127.0.0.0/8 -j ACCEPT
iptables -A INPUT -s 127.0.0.0/8 -d 127.0.0.0/8 -j ACCEPT

iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

if command -v ipset >/dev/null 2>&1; then
    ipset destroy allowed-domains 2>/dev/null || true
    ipset create allowed-domains hash:net
    
    for domain in api.anthropic.com console.anthropic.com; do
        ips=$(getent hosts $domain | awk '{print $1}')
        for ip in $ips; do
            ipset add allowed-domains $ip 2>/dev/null || true
        done
    done
    
    iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
else
    iptables -A OUTPUT -d api.anthropic.com -j ACCEPT
    iptables -A OUTPUT -d console.anthropic.com -j ACCEPT
fi

iptables -P OUTPUT DROP
iptables -P INPUT DROP

echo "Firewall initialized with Anthropic-only access"
rm -f "$0"
FIREWALLEOF

RUN chmod +x ~/init-firewall.sh

RUN mkdir -p ~/.config/claude && \
   cat > ~/.config/claude/config.json << CONFIGEOF
{
  "mcpServers": {
    "thinking": {
      "command": "/home/$USERNAME/mcp-servers/run-thinking.sh",
      "args": []
    },
    "memory": {
      "command": "/home/$USERNAME/mcp-servers/run-memory.sh",
      "args": [],
      "env": {
        "MEMORY_FILE_PATH": "/home/$USERNAME/.claudebox/memory.json"
      }
    }
  }
}
CONFIGEOF

RUN bash -c "source $NVM_DIR/nvm.sh && claude --version"


RUN echo '#!/bin/bash' > ~/claude-wrapper && \
   echo 'export NVM_DIR="$HOME/.nvm"' >> ~/claude-wrapper && \
   echo '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' >> ~/claude-wrapper && \
   echo '' >> ~/claude-wrapper && \
   echo '# Filter out security flags before passing to claude' >> ~/claude-wrapper && \
   echo 'FILTERED_ARGS=()' >> ~/claude-wrapper && \
   echo 'for arg in "$@"; do' >> ~/claude-wrapper && \
   echo '    case "$arg" in' >> ~/claude-wrapper && \
   echo '        --dangerously-enable-sudo|--dangerously-disable-firewall) ;;' >> ~/claude-wrapper && \
   echo '        *) FILTERED_ARGS+=("$arg") ;;' >> ~/claude-wrapper && \
   echo '    esac' >> ~/claude-wrapper && \
   echo 'done' >> ~/claude-wrapper && \
   echo '' >> ~/claude-wrapper && \
   echo 'exec claude "${FILTERED_ARGS[@]}"' >> ~/claude-wrapper && \
   chmod +x ~/claude-wrapper

WORKDIR /workspace

USER root
RUN echo '#!/bin/bash' > /usr/local/bin/docker-entrypoint && \
   echo 'ENABLE_SUDO=false' >> /usr/local/bin/docker-entrypoint && \
   echo 'DISABLE_FIREWALL=false' >> /usr/local/bin/docker-entrypoint && \
   echo 'for arg in "$@"; do' >> /usr/local/bin/docker-entrypoint && \
   echo '    case "$arg" in' >> /usr/local/bin/docker-entrypoint && \
   echo '        --dangerously-enable-sudo) ENABLE_SUDO=true ;;' >> /usr/local/bin/docker-entrypoint && \
   echo '        --dangerously-disable-firewall) DISABLE_FIREWALL=true ;;' >> /usr/local/bin/docker-entrypoint && \
   echo '    esac' >> /usr/local/bin/docker-entrypoint && \
   echo 'done' >> /usr/local/bin/docker-entrypoint && \
   echo '' >> /usr/local/bin/docker-entrypoint && \
   echo '# Run firewall setup AS ROOT before switching users' >> /usr/local/bin/docker-entrypoint && \
   echo 'export DISABLE_FIREWALL' >> /usr/local/bin/docker-entrypoint && \
   echo "if [ -f /home/$USERNAME/init-firewall.sh ]; then" >> /usr/local/bin/docker-entrypoint && \
   echo "    /home/$USERNAME/init-firewall.sh || true" >> /usr/local/bin/docker-entrypoint && \
   echo 'fi' >> /usr/local/bin/docker-entrypoint && \
   echo '' >> /usr/local/bin/docker-entrypoint && \
   echo '# NOW handle sudo setup if needed' >> /usr/local/bin/docker-entrypoint && \
   echo 'if [ "$ENABLE_SUDO" = "true" ]; then' >> /usr/local/bin/docker-entrypoint && \
   echo "    echo \"$USERNAME ALL=(ALL) NOPASSWD:ALL\" > /etc/sudoers.d/$USERNAME" >> /usr/local/bin/docker-entrypoint && \
   echo "    chmod 0440 /etc/sudoers.d/$USERNAME" >> /usr/local/bin/docker-entrypoint && \
   echo 'fi' >> /usr/local/bin/docker-entrypoint && \
   echo '' >> /usr/local/bin/docker-entrypoint && \
   echo '# Switch to user directory first' >> /usr/local/bin/docker-entrypoint && \
   echo "cd /home/$USERNAME" >> /usr/local/bin/docker-entrypoint && \
   echo '' >> /usr/local/bin/docker-entrypoint && \
   echo '# Finally switch to user and run command' >> /usr/local/bin/docker-entrypoint && \
   echo "exec su $USERNAME -c \"cd /workspace && /home/$USERNAME/claude-wrapper \\\"\\\$@\\\"\"" >> /usr/local/bin/docker-entrypoint && \
   chmod +x /usr/local/bin/docker-entrypoint
ENTRYPOINT ["/usr/local/bin/docker-entrypoint"]
EOF

progress_install() {
   local label="$1"
   local pct="$2"
   local bar_length=30
   local filled=$(( pct * bar_length / 100 ))
   local empty=$(( bar_length - filled ))
   local bar=$(printf "%0.s#" $(seq 1 $filled))
   local spaces=$(printf "%0.s " $(seq 1 $empty))
   printf "\r%-20s [%s%s] %3d%%" "$label" "$bar" "$spaces" "$pct"
   if [ "$pct" -eq 100 ]; then
       echo
   fi
}

   for i in {0..100..5}; do
       progress_install "Docker image" $i
       sleep 0.1
   done &
   PROGRESS_PID=$!

   confirm_action 1 "Build the ClaudeBox Docker image '$IMAGE_NAME'. This may take some time." "build_image"
   echo -e "${BLUE}Starting Docker image build...${NC}"
   # Actual build command (verbose output, was already like this)
   docker build \
       --build-arg USER_ID="$USER_ID" \
       --build-arg GROUP_ID="$GROUP_ID" \
       --build-arg USERNAME="$DOCKER_USER" \
       --build-arg NODE_VERSION="$NODE_VERSION" \
       -f "$DOCKERFILE" -t "$IMAGE_NAME" "$PROJECT_DIR" 2>&1 | grep -v 'invoke-rc.d' | grep -v 'policy-rc.d' || true

   # Ensure spinner finishes and correct message is shown
   if kill -0 $PROGRESS_PID 2>/dev/null; then # Check if spinner PID is running
      kill $PROGRESS_PID 2>/dev/null || true # kill it
      wait $PROGRESS_PID 2>/dev/null || true # wait for it to be reaped
   fi
   progress_install "Docker image" 100 # Mark as complete regardless of spinner's actual state due to build output
   echo # Newline after spinner

   # Verify image was built
   if ! docker image inspect "$IMAGE_NAME" >/dev/null 2>&1; then
        echo -e "${RED}Error: Docker image '$IMAGE_NAME' failed to build. Please check the output above.${NC}"
        rm -f "$DOCKERFILE"
        exit 1
   fi

   rm -f "$DOCKERFILE"
   echo -e "${GREEN}Docker image '$IMAGE_NAME' successfully built!${NC}"
   first_time=true
fi

# Install global symlink if needed
if [[ ! -L "$LINK_TARGET" || "$(readlink "$LINK_TARGET")" != "$SCRIPT_PATH" ]]; then
    echo -e "${BLUE}Global symlink for 'claudebox' needs attention.${NC}"
    if [[ -w "$(dirname "$LINK_TARGET")" ]]; then
        confirm_action 1 "Create/update global symlink for 'claudebox' at '$LINK_TARGET'." "create_symlink"
        # Remove existing if it's a broken symlink or points elsewhere, or a non-symlink file
        if [[ -e "$LINK_TARGET" ]]; then rm -f "$LINK_TARGET"; fi
        ln -s "$SCRIPT_PATH" "$LINK_TARGET"
        echo -e "${GREEN}'claudebox' symlink created/updated at $LINK_TARGET!${NC}"
    else
        confirm_action 2 "Create/update global symlink for 'claudebox' at '$LINK_TARGET'. This requires sudo." "create_symlink_sudo"
        echo -e "${BLUE}Attempting to create/update symlink using sudo...${NC}"
        # Remove existing if it's a broken symlink or points elsewhere, or a non-symlink file
        if [[ -e "$LINK_TARGET" ]]; then sudo rm -f "$LINK_TARGET"; fi
        sudo ln -s "$SCRIPT_PATH" "$LINK_TARGET"
        echo -e "${GREEN}'claudebox' symlink created/updated at $LINK_TARGET using sudo!${NC}"
    fi
fi

# Show welcome message on first run
if [[ "$first_time" == true ]]; then
   echo
   echo -e "${CYAN}ClaudeBox Setup Complete!${NC}"
   echo
   echo -e "${GREEN}Quick Start:${NC}"
   echo -e "  ${YELLOW}claudebox [options]${NC}        # Launch Claude CLI"
   echo
   echo -e "${GREEN}Power Features:${NC}"
   echo -e "  ${YELLOW}claudebox profile${NC}                # See all language profiles"
   echo -e "  ${YELLOW}claudebox profile c openwrt${NC}      # Install C + OpenWRT tools"
   echo -e "  ${YELLOW}claudebox profile python ml${NC}      # Install Python + ML stack"
   echo -e "  ${YELLOW}claudebox install <packages>${NC}     # Install additional apt packages"
   echo -e "  ${YELLOW}claudebox shell${NC}                  # Open bash shell in container"
   echo
   echo -e "${GREEN}Security:${NC}"
   echo -e "  Network firewall: ON by default (Anthropic recommended)"
   echo -e "  Sudo access: OFF by default"
   echo
   echo -e "${PURPLE}Just install the profile you need and start coding!${NC}"
   exit 0
fi

docker run -it --rm \
   -w /workspace \
   -v "$PROJECT_DIR":/workspace \
   -v "$CLAUDE_DATA_DIR":/home/$DOCKER_USER/.claude \
   -v "$HOME/.claudebox":/home/$DOCKER_USER/.claudebox \
   -v "$HOME/.config/claude":/home/$DOCKER_USER/.config/claude \
   -v "$HOME/.claude.json":/home/$DOCKER_USER/.claude.json \
   -v "$HOME/.npmrc":/home/$DOCKER_USER/.npmrc:ro \
   -v "$HOME/.ssh":/home/$DOCKER_USER/.ssh:ro \
   -e "NODE_ENV=${NODE_ENV:-production}" \
   -e "ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}" \
   --cap-add NET_ADMIN \
   --cap-add NET_RAW \
   "$IMAGE_NAME" "${USER_ARGS[@]}"
